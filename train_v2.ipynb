{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gwilliams2023 with batch type audiotext\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "onset",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "duration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "word",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d54129e4-e593-4325-8969-f846db88ecef",
       "rows": [
        [
         "0",
         "23.506",
         "0.3",
         "Tara"
        ],
        [
         "1",
         "23.816",
         "0.24",
         "stood"
        ],
        [
         "2",
         "24.056",
         "0.37",
         "stock"
        ],
        [
         "3",
         "24.586",
         "0.3999999999999999",
         "still"
        ],
        [
         "4",
         "25.136",
         "0.4100000000000001",
         "waiting"
        ],
        [
         "5",
         "25.546",
         "0.1299999999999999",
         "for"
        ],
        [
         "6",
         "25.676",
         "0.0899999999999998",
         "the"
        ],
        [
         "7",
         "25.766",
         "0.27",
         "first"
        ],
        [
         "8",
         "26.046",
         "0.31",
         "tiny"
        ],
        [
         "9",
         "26.356",
         "0.2399999999999997",
         "gleam"
        ],
        [
         "10",
         "26.606",
         "0.1799999999999997",
         "from"
        ],
        [
         "11",
         "26.786",
         "0.0700000000000002",
         "the"
        ],
        [
         "12",
         "26.856",
         "0.29",
         "scout"
        ],
        [
         "13",
         "27.146",
         "0.29",
         "craft"
        ],
        [
         "14",
         "27.446",
         "0.1499999999999999",
         "to"
        ],
        [
         "15",
         "27.596",
         "0.2800000000000002",
         "appear"
        ],
        [
         "16",
         "27.876",
         "0.08",
         "in"
        ],
        [
         "17",
         "27.956",
         "0.0899999999999998",
         "the"
        ],
        [
         "18",
         "28.046",
         "0.4199999999999999",
         "darkness"
        ],
        [
         "19",
         "28.466",
         "0.1399999999999996",
         "of"
        ],
        [
         "20",
         "28.606",
         "0.0900000000000007",
         "the"
        ],
        [
         "21",
         "29.756",
         "0.1399999999999996",
         "The"
        ],
        [
         "22",
         "29.896",
         "0.3900000000000005",
         "gentle"
        ],
        [
         "23",
         "30.286",
         "0.4199999999999999",
         "constant"
        ],
        [
         "24",
         "30.706",
         "0.2099999999999999",
         "breeze"
        ],
        [
         "25",
         "30.916",
         "0.1200000000000001",
         "of"
        ],
        [
         "26",
         "31.036",
         "0.4100000000000001",
         "recycled"
        ],
        [
         "27",
         "31.476",
         "0.160000000000001",
         "air"
        ],
        [
         "28",
         "31.636",
         "0.1599999999999983",
         "from"
        ],
        [
         "29",
         "31.796",
         "0.0900000000000016",
         "the"
        ],
        [
         "30",
         "31.886",
         "0.2399999999999984",
         "vent"
        ],
        [
         "31",
         "32.126",
         "0.200000000000001",
         "above"
        ],
        [
         "32",
         "32.336",
         "0.1999999999999993",
         "blew"
        ],
        [
         "33",
         "32.536",
         "0.1100000000000012",
         "an"
        ],
        [
         "34",
         "32.646",
         "0.3900000000000005",
         "annoying"
        ],
        [
         "35",
         "33.036",
         "0.1699999999999999",
         "hair"
        ],
        [
         "36",
         "33.206",
         "0.3500000000000014",
         "against"
        ],
        [
         "37",
         "33.556",
         "0.1399999999999988",
         "her"
        ],
        [
         "38",
         "33.696",
         "0.3900000000000005",
         "nose"
        ],
        [
         "39",
         "34.246",
         "0.1999999999999993",
         "but"
        ],
        [
         "40",
         "34.446",
         "0.1699999999999999",
         "she"
        ],
        [
         "41",
         "34.616",
         "0.3000000000000007",
         "ignored"
        ],
        [
         "42",
         "34.916",
         "0.1600000000000001",
         "it"
        ],
        [
         "43",
         "35.396",
         "0.1100000000000012",
         "A"
        ],
        [
         "44",
         "35.506",
         "0.4700000000000006",
         "gasp"
        ],
        [
         "45",
         "35.986",
         "0.2699999999999996",
         "from"
        ],
        [
         "46",
         "36.256",
         "0.1300000000000007",
         "the"
        ],
        [
         "47",
         "36.386",
         "0.5399999999999991",
         "psychic"
        ],
        [
         "48",
         "36.926",
         "0.3200000000000003",
         "broke"
        ],
        [
         "49",
         "37.256",
         "0.1999999999999993",
         "her"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 668
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.506</td>\n",
       "      <td>0.30</td>\n",
       "      <td>Tara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.816</td>\n",
       "      <td>0.24</td>\n",
       "      <td>stood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.056</td>\n",
       "      <td>0.37</td>\n",
       "      <td>stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.586</td>\n",
       "      <td>0.40</td>\n",
       "      <td>still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.136</td>\n",
       "      <td>0.41</td>\n",
       "      <td>waiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>361.097</td>\n",
       "      <td>0.17</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>361.277</td>\n",
       "      <td>0.14</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>361.487</td>\n",
       "      <td>0.58</td>\n",
       "      <td>project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>362.207</td>\n",
       "      <td>0.15</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>362.817</td>\n",
       "      <td>0.34</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       onset  duration     word\n",
       "0     23.506      0.30     Tara\n",
       "1     23.816      0.24    stood\n",
       "2     24.056      0.37    stock\n",
       "3     24.586      0.40    still\n",
       "4     25.136      0.41  waiting\n",
       "..       ...       ...      ...\n",
       "663  361.097      0.17      end\n",
       "664  361.277      0.14      for\n",
       "665  361.487      0.58  project\n",
       "666  362.207      0.15      and\n",
       "667  362.817      0.34  species\n",
       "\n",
       "[668 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from studies.gwilliams2023 import Gwilliams2023\n",
    "from studies.armeini2022 import Armeini2022\n",
    "\n",
    "\n",
    "study = Gwilliams2023(\n",
    "    batch_type=\"audiotext\",\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "rec = study.recordings[0][0][0]\n",
    "raw = rec.load_raw(load_data=True)\n",
    "events = rec.load_events(raw, options=\"both\")\n",
    "word_events = events[\"word\"]\n",
    "word_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 20:08:31,422\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "from dataloader import DataLoader\n",
    "\n",
    "add_timestamps = True\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    buffer_size=30,\n",
    "    max_cache_size_gb=400,\n",
    "    cache_dir=\"cache\",\n",
    "    notch_filter=True,\n",
    "    frequency_bands={\"all\": (0.5, 80)},\n",
    "    scaling=\"both\",\n",
    "    brain_clipping=None,\n",
    "    baseline_window=0.5,\n",
    "    new_freq=200,\n",
    "    delay=0.15,\n",
    "    batch_types={\"audiotext\": 1},\n",
    "    batch_kwargs={\n",
    "        \"audiotext\": {\n",
    "            \"max_random_shift\": 1.0,\n",
    "            \"window_size\": 4,\n",
    "            \"window_stride\": 1,\n",
    "            \"audio_sample_rate\": 16000,\n",
    "            \"hop_length\": 160,\n",
    "            \"audio_processor\": \"openai/whisper-tiny.en\",\n",
    "            \"add_timestamps\": add_timestamps,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "dataloader.start_fetching(recordings=[rec])\n",
    "batch = dataloader.get_recording()\n",
    "\n",
    "brain, audio, recording = (\n",
    "    batch.brain_segments[\"all\"], # .to(device)\n",
    "    batch.audio_segments, # .to(device)\n",
    "    recording\n",
    "    batch.recording,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train.training_session_v1 import load_training_session\n",
    "# import multiprocessing\n",
    "# import torch\n",
    "\n",
    "# device = \"cuda\"\n",
    "\n",
    "# session = load_training_session(\n",
    "#     save_path=\"saves/phase2/architecture/task/transformers/4C4Con_d256/epoch_39\",\n",
    "#     studies={\"gwilliams2023\": \"audio\"},\n",
    "#     data_path=\"/home/ubuntu/storage-texas/data\",\n",
    "#     cache_name=\"cache\",\n",
    "# )\n",
    "\n",
    "# dataloader = session.get_dataloader(buffer_size=1, num_workers=1, max_cache_size=100)\n",
    "\n",
    "# # Unseen both\n",
    "# # recording = session.studies[\"gwilliams2023\"].recordings[19][0][0]\n",
    "\n",
    "# # Seen\n",
    "# # recording = session.studies[\"gwilliams2023\"].recordings[15][0][1]\n",
    "\n",
    "# # Unseen task\n",
    "# # recording = session.studies[\"gwilliams2023\"].recordings[18][0][0]\n",
    "\n",
    "# # Unseen subject\n",
    "# recording = session.studies[\"gwilliams2023\"].recordings[19][0][1]\n",
    "\n",
    "# print(\n",
    "#     f\"Showing recording: {recording.study_name}_{recording.subject_id}_{recording.task_id}\"\n",
    "# )\n",
    "\n",
    "# dataloader.start_fetching(recordings=[recording])\n",
    "# batch = dataloader.get_recording()\n",
    "# brain, audio, recording = (\n",
    "#     batch.brain_segments[\"all\"].to(device),\n",
    "#     batch.audio_segments.to(device),\n",
    "#     batch.recording,\n",
    "# )\n",
    "\n",
    "# conditions = {\n",
    "#     \"study\": f\"{recording.study_name}\",\n",
    "#     \"subject\": f\"{recording.study_name}_{recording.subject_id}\",\n",
    "# }\n",
    "# session.model.to(device).eval()\n",
    "\n",
    "# # with torch.no_grad():\n",
    "# #     (\n",
    "# #         x,  # [B, C, T]\n",
    "# #         quantizer_metrics,\n",
    "# #         channel_weights,\n",
    "# #         hidden_outputs,\n",
    "# #         encoder_hidden_states,  # L * [B, T, D]\n",
    "# #     ) = session.model(\n",
    "# #         x=[brain],\n",
    "# #         recording=[recording],\n",
    "# #         conditions=[conditions],\n",
    "# #         mel=[audio],\n",
    "# #         train=False,\n",
    "# #         return_hidden_outputs=False,\n",
    "# #     )\n",
    "\n",
    "# dataloader.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
