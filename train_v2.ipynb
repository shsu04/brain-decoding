{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gwilliams2023 with batch type audiotext\n",
      "Loading Armeini2022 with batch type audiotext\n",
      "Data partitioned on studies ['gwilliams2023', 'armeini2022'].\n",
      "Train: 159, Unseen Task: 51, Unseen Subject: 12, Unseen Both: 4.\n",
      "\n",
      "RNNEncoder initialized as conformer with 4 layers, 256 d_model, 4 nhead\n",
      "\tEmbedding: sinusoidal, params: 6075392\n",
      "SimpleConv initialized with 10274922 parameters, cond: ['study']\n",
      "Merger True, merger channels 269\n",
      "ConvBlocks: 4, hidden_dim: 256, params 2626048\n",
      "Using torch.bfloat16\n",
      "Found 64 target modules for AdaLora: ['model.encoder.layers.0.self_attn.k_proj', 'model.encoder.layers.0.self_attn.v_proj', 'model.encoder.layers.0.self_attn.q_proj', 'model.encoder.layers.0.self_attn.out_proj', 'model.encoder.layers.0.fc1', 'model.encoder.layers.0.fc2', 'model.encoder.layers.1.self_attn.k_proj', 'model.encoder.layers.1.self_attn.v_proj', 'model.encoder.layers.1.self_attn.q_proj', 'model.encoder.layers.1.self_attn.out_proj', 'model.encoder.layers.1.fc1', 'model.encoder.layers.1.fc2', 'model.encoder.layers.2.self_attn.k_proj', 'model.encoder.layers.2.self_attn.v_proj', 'model.encoder.layers.2.self_attn.q_proj', 'model.encoder.layers.2.self_attn.out_proj', 'model.encoder.layers.2.fc1', 'model.encoder.layers.2.fc2', 'model.encoder.layers.3.self_attn.k_proj', 'model.encoder.layers.3.self_attn.v_proj', 'model.encoder.layers.3.self_attn.q_proj', 'model.encoder.layers.3.self_attn.out_proj', 'model.encoder.layers.3.fc1', 'model.encoder.layers.3.fc2', 'model.decoder.layers.0.self_attn.k_proj', 'model.decoder.layers.0.self_attn.v_proj', 'model.decoder.layers.0.self_attn.q_proj', 'model.decoder.layers.0.self_attn.out_proj', 'model.decoder.layers.0.encoder_attn.k_proj', 'model.decoder.layers.0.encoder_attn.v_proj', 'model.decoder.layers.0.encoder_attn.q_proj', 'model.decoder.layers.0.encoder_attn.out_proj', 'model.decoder.layers.0.fc1', 'model.decoder.layers.0.fc2', 'model.decoder.layers.1.self_attn.k_proj', 'model.decoder.layers.1.self_attn.v_proj', 'model.decoder.layers.1.self_attn.q_proj', 'model.decoder.layers.1.self_attn.out_proj', 'model.decoder.layers.1.encoder_attn.k_proj', 'model.decoder.layers.1.encoder_attn.v_proj', 'model.decoder.layers.1.encoder_attn.q_proj', 'model.decoder.layers.1.encoder_attn.out_proj', 'model.decoder.layers.1.fc1', 'model.decoder.layers.1.fc2', 'model.decoder.layers.2.self_attn.k_proj', 'model.decoder.layers.2.self_attn.v_proj', 'model.decoder.layers.2.self_attn.q_proj', 'model.decoder.layers.2.self_attn.out_proj', 'model.decoder.layers.2.encoder_attn.k_proj', 'model.decoder.layers.2.encoder_attn.v_proj', 'model.decoder.layers.2.encoder_attn.q_proj', 'model.decoder.layers.2.encoder_attn.out_proj', 'model.decoder.layers.2.fc1', 'model.decoder.layers.2.fc2', 'model.decoder.layers.3.self_attn.k_proj', 'model.decoder.layers.3.self_attn.v_proj', 'model.decoder.layers.3.self_attn.q_proj', 'model.decoder.layers.3.self_attn.out_proj', 'model.decoder.layers.3.encoder_attn.k_proj', 'model.decoder.layers.3.encoder_attn.v_proj', 'model.decoder.layers.3.encoder_attn.q_proj', 'model.decoder.layers.3.encoder_attn.out_proj', 'model.decoder.layers.3.fc1', 'model.decoder.layers.3.fc2']\n",
      "openai/whisper-tiny.en loaded with total params = 38572096. 811776 are trainable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 15:03:34,308\tINFO worker.py:1841 -- Started a local Ray instance.\n",
      "Training Epoch 1: 100%|██████████| 159/159 [19:08<00:00,  7.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 7.30m.\n",
      "Epoch 1 done in 26.52m. 0.17m/recording.\n",
      "\n",
      "\n",
      "New best epoch 1 with CER 2.3982 and BLEU 0.0038.\n",
      "Mel Loss: 6.6745, Clip Loss: 9.5204, MSE: 2.4056\n",
      "Mel accuracy: 0.0045, Top 5: 0.0226, Top 10: 0.0446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 19832 MiB, 27 objects, write throughput 782 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "Training Epoch 2: 100%|██████████| 159/159 [19:08<00:00,  7.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.00m.\n",
      "Epoch 2 done in 23.15m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 2 with CER 0.9296 and BLEU 0.0032.\n",
      "Mel Loss: 5.9366, Clip Loss: 9.5189, MSE: 0.5631\n",
      "Mel accuracy: 0.0046, Top 5: 0.0226, Top 10: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 46413 MiB, 54 objects, write throughput 804 MiB/s.\n",
      "Training Epoch 3: 100%|██████████| 159/159 [18:56<00:00,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.87m.\n",
      "Epoch 3 done in 22.81m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 3 with CER 0.9008 and BLEU 0.0110.\n",
      "Mel Loss: 5.8215, Clip Loss: 9.5231, MSE: 0.2692\n",
      "Mel accuracy: 0.0044, Top 5: 0.0220, Top 10: 0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:   0%|          | 0/159 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rank reallocation at recording 1962.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 159/159 [19:09<00:00,  7.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.88m.\n",
      "Epoch 4 done in 23.04m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 4 with CER 0.9008 and BLEU 0.0110.\n",
      "Mel Loss: 5.7960, Clip Loss: 9.5140, MSE: 0.2190\n",
      "Mel accuracy: 0.0045, Top 5: 0.0219, Top 10: 0.0441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 159/159 [19:11<00:00,  7.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.39m.\n",
      "Epoch 5 done in 22.58m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 70946 MiB, 81 objects, write throughput 806 MiB/s.\n",
      "Training Epoch 6: 100%|██████████| 159/159 [19:18<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.88m.\n",
      "Epoch 6 done in 24.20m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 6 with CER 1.0244 and BLEU 0.0138.\n",
      "Mel Loss: 5.7862, Clip Loss: 9.5135, MSE: 0.1953\n",
      "Mel accuracy: 0.0045, Top 5: 0.0221, Top 10: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 159/159 [19:04<00:00,  7.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.38m.\n",
      "Epoch 7 done in 22.45m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 7 with CER 0.9561 and BLEU 0.0012.\n",
      "Mel Loss: 5.8369, Clip Loss: 9.5570, MSE: 0.2568\n",
      "Mel accuracy: 0.0045, Top 5: 0.0219, Top 10: 0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 159/159 [19:06<00:00,  7.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.30m.\n",
      "Epoch 8 done in 23.42m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 8 with CER 0.9152 and BLEU 0.0154.\n",
      "Mel Loss: 6.0105, Clip Loss: 9.6510, MSE: 0.5497\n",
      "Mel accuracy: 0.0045, Top 5: 0.0223, Top 10: 0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 96069 MiB, 108 objects, write throughput 805 MiB/s.\n",
      "\u001b[36m(raylet)\u001b[0m Spilled 98457 MiB, 109 objects, write throughput 806 MiB/s.\n",
      "\u001b[36m(raylet)\u001b[0m Spilled 108404 MiB, 120 objects, write throughput 832 MiB/s.\n",
      "Training Epoch 9: 100%|██████████| 159/159 [19:14<00:00,  7.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.52m.\n",
      "Epoch 9 done in 22.76m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 9 with CER 0.9066 and BLEU 0.0075.\n",
      "Mel Loss: 5.9945, Clip Loss: 9.5652, MSE: 0.6385\n",
      "Mel accuracy: 0.0046, Top 5: 0.0219, Top 10: 0.0441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 159/159 [19:08<00:00,  7.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.24m.\n",
      "Epoch 10 done in 23.39m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 10 with CER 0.9155 and BLEU 0.0154.\n",
      "Mel Loss: 6.0015, Clip Loss: 9.5699, MSE: 0.6490\n",
      "Mel accuracy: 0.0044, Top 5: 0.0222, Top 10: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 159/159 [19:04<00:00,  7.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.39m.\n",
      "Epoch 11 done in 23.48m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 159/159 [18:58<00:00,  7.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.52m.\n",
      "Epoch 12 done in 23.51m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 141353 MiB, 161 objects, write throughput 824 MiB/s.\n",
      "Training Epoch 13: 100%|██████████| 159/159 [19:09<00:00,  7.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 5.42m.\n",
      "Epoch 13 done in 24.58m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 159/159 [18:56<00:00,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.96m.\n",
      "Epoch 14 done in 23.91m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 159/159 [19:06<00:00,  7.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.61m.\n",
      "Epoch 15 done in 23.73m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 159/159 [19:07<00:00,  7.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.40m.\n",
      "Epoch 16 done in 23.54m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 159/159 [19:01<00:00,  7.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.78m.\n",
      "Epoch 17 done in 22.81m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 17 with CER 0.9093 and BLEU 0.0078.\n",
      "Mel Loss: 6.7873, Clip Loss: 9.6785, MSE: 2.4506\n",
      "Mel accuracy: 0.0045, Top 5: 0.0222, Top 10: 0.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 159/159 [19:07<00:00,  7.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.35m.\n",
      "Epoch 18 done in 23.47m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 18 with CER 0.9423 and BLEU 0.0098.\n",
      "Mel Loss: 7.2453, Clip Loss: 9.8175, MSE: 3.3869\n",
      "Mel accuracy: 0.0043, Top 5: 0.0220, Top 10: 0.0440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 159/159 [18:59<00:00,  7.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.39m.\n",
      "Epoch 19 done in 22.38m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 159/159 [18:38<00:00,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.09m.\n",
      "Epoch 20 done in 22.74m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 20 with CER 0.9178 and BLEU 0.0144.\n",
      "Mel Loss: 7.5965, Clip Loss: 9.9670, MSE: 4.0406\n",
      "Mel accuracy: 0.0044, Top 5: 0.0221, Top 10: 0.0437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 159/159 [18:43<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.04m.\n",
      "Epoch 21 done in 22.77m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 21 with CER 0.9095 and BLEU 0.0125.\n",
      "Mel Loss: 7.6626, Clip Loss: 10.0085, MSE: 4.1439\n",
      "Mel accuracy: 0.0045, Top 5: 0.0225, Top 10: 0.0446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22: 100%|██████████| 159/159 [18:37<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.98m.\n",
      "Epoch 22 done in 22.61m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 159/159 [18:38<00:00,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.13m.\n",
      "Epoch 23 done in 22.78m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 23 with CER 0.9154 and BLEU 0.0154.\n",
      "Mel Loss: 8.0027, Clip Loss: 10.0975, MSE: 4.8605\n",
      "Mel accuracy: 0.0043, Top 5: 0.0221, Top 10: 0.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 159/159 [18:44<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.43m.\n",
      "Epoch 24 done in 22.17m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 159/159 [18:34<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.37m.\n",
      "Epoch 25 done in 21.94m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 159/159 [18:35<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.68m.\n",
      "Epoch 26 done in 22.27m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27: 100%|██████████| 159/159 [18:47<00:00,  7.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.88m.\n",
      "Epoch 27 done in 23.67m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 285308 MiB, 323 objects, write throughput 858 MiB/s.\n",
      "Training Epoch 28: 100%|██████████| 159/159 [18:43<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.40m.\n",
      "Epoch 28 done in 22.13m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 159/159 [18:38<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.39m.\n",
      "Epoch 29 done in 23.03m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 29 with CER 0.9067 and BLEU 0.0142.\n",
      "Mel Loss: 8.4213, Clip Loss: 10.1859, MSE: 5.7745\n",
      "Mel accuracy: 0.0044, Top 5: 0.0227, Top 10: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 159/159 [18:40<00:00,  7.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.01m.\n",
      "Epoch 30 done in 22.69m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 159/159 [18:42<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.96m.\n",
      "Epoch 31 done in 22.67m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32: 100%|██████████| 159/159 [18:36<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.80m.\n",
      "Epoch 32 done in 22.41m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 159/159 [18:44<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.71m.\n",
      "Epoch 33 done in 22.45m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 159/159 [18:36<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.33m.\n",
      "Epoch 34 done in 22.94m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 159/159 [18:43<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.90m.\n",
      "Epoch 35 done in 22.62m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 159/159 [18:40<00:00,  7.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.29m.\n",
      "Epoch 36 done in 22.97m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.      | 20/159 [03:08<16:08,  6.97s/it] \n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\u001b[36m(raylet)\u001b[0m Spilled 536508 MiB, 594 objects, write throughput 895 MiB/s.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# del session.logger\n",
    "# del session.epoch_logger\n",
    "# del session\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "import multiprocessing\n",
    "from train.training_session_v2 import TrainingSessionV2, load_training_session\n",
    "from config import TrainingConfigV2\n",
    "from config import SimpleConvConfig\n",
    "\n",
    "data_partition = {\n",
    "    \"gwilliams2023\": {\n",
    "        \"testing_subjects\": [19, 20, 21],\n",
    "        \"testing_tasks\": [0],\n",
    "    },\n",
    "    \"armeini2022\": {\n",
    "        \"testing_subjects\": [],\n",
    "        \"testing_tasks\": [0, 1],\n",
    "    },\n",
    "}\n",
    "\n",
    "model_config = SimpleConvConfig(\n",
    "    # Str to list of possible conditions\n",
    "    mel_normalization=False,\n",
    "    conditions={\n",
    "        \"study\": [],\n",
    "        \"subject\": [],\n",
    "    },\n",
    "    # Channels\n",
    "    in_channels=208,\n",
    "    out_channels=80,\n",
    "    hidden_dim=256,\n",
    "    dropout=0.2,\n",
    "    initial_batch_norm=True,\n",
    "    # # Sensor layout settings\n",
    "    # layout_dim=2,\n",
    "    # layout_proj=True,\n",
    "    # layout_scaling=\"minmax\",\n",
    "    # # Merger with spatial attn\n",
    "    # merger=False,\n",
    "    # merger_emb_type=None,\n",
    "    # merger_emb_dim=0,\n",
    "    # merger_channels=0,\n",
    "    # merger_dropout=0.0,  # Float\n",
    "    # merger_conditional=None,\n",
    "    # Inital\n",
    "    initial_linear=256,\n",
    "    initial_depth=1,\n",
    "    # Conditional layers\n",
    "    conditional_layers=False,\n",
    "    conditional_layers_dim=None,  # input or hidden_dim\n",
    "    # Conv layer overall structure\n",
    "    depth=4,\n",
    "    kernel_size=3,\n",
    "    growth=1.0,\n",
    "    dilation_growth=2,\n",
    "    dilation_period=5,\n",
    "    glu=1,\n",
    "    conv_dropout=0.2,\n",
    "    dropout_input=0.1,\n",
    "    batch_norm=True,\n",
    "    half=True,\n",
    "    cnn_pos_encoding=False,\n",
    "    # Quantizer\n",
    "    quantizer=False,\n",
    "    num_codebooks=0,\n",
    "    codebook_size=0,\n",
    "    quantizer_commitment=0,\n",
    "    quantizer_temp_init=0,\n",
    "    quantizer_temp_min=0,\n",
    "    quantizer_temp_decay=0,\n",
    "    # Transformers Encoders\n",
    "    transformer_input=\"continuous\",\n",
    "    transformer_encoder_emb=\"sinusoidal\",\n",
    "    transformer_encoder_layers=4,\n",
    "    transformer_encoder_heads=4,\n",
    "    # Conformer encoder variant\n",
    "    rnn_type=\"conformer\",\n",
    "    depthwise_conv_kernel_size=15,\n",
    "    use_group_norm=False,\n",
    "    convolution_first=False,\n",
    "    # Transformer Decoders\n",
    "    transformer_decoder_emb=None,\n",
    "    transformer_decoder_layers=0,\n",
    "    transformer_decoder_heads=0,\n",
    "    transformer_decoder_dim=0,\n",
    ")\n",
    "\n",
    "config = TrainingConfigV2(\n",
    "    brain_encoder_config=model_config,\n",
    "    data_partition=data_partition,\n",
    "    # Ada lora settings\n",
    "    # Around 100k total batches an epoch for gwilliams\n",
    "    use_adalora=True,\n",
    "    adalora_init_r=12,\n",
    "    adalora_target_r=4,\n",
    "    adalora_tinit=(654 * 3),  # 5% total steps\n",
    "    adalora_tfinal=(654 * 8),  # 50-80% total steps\n",
    "    adalora_deltaT=(654 * 1),  # 1-5% total steps\n",
    "    adalora_lora_alpha=32,\n",
    "    adalora_lora_dropout=0.1,\n",
    "    adalora_total_step=(654 * 50),\n",
    "    # Pre-processing parameters\n",
    "    # Brain\n",
    "    new_freq=200,\n",
    "    frequency_bands={\"all\": (0.5, 80)},\n",
    "    max_random_shift=1.0,\n",
    "    window_size=4,\n",
    "    window_stride=1,\n",
    "    brain_clipping=None,\n",
    "    baseline_window=0.5,\n",
    "    notch_filter=True,\n",
    "    scaling=\"both\",\n",
    "    delay=0.15,\n",
    "    # Audio\n",
    "    audio_model=\"openai/whisper-tiny.en\",\n",
    "    # Hyperparameters\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=450, # 654,\n",
    "    batch_size=128,\n",
    "    random_test_size=10,\n",
    "    seed=42,\n",
    "    mel_alignment_objectives = {\n",
    "        \"clip_loss\": 0.6,\n",
    "        \"mse_loss\": 0.4\n",
    "    },\n",
    "    latent_alignment_objectives= {\n",
    "        \"cosine_similarity\": 0.4,\n",
    "        \"mse_loss\": 0.4,\n",
    "        \"clip_loss\": 0.6,\n",
    "        \"mmd_loss\": 0.0\n",
    "    },\n",
    "    decode_timestamps=True,\n",
    ")\n",
    "\n",
    "config.brain_encoder_config.mel_normalization = False\n",
    "config.learning_rate = 3e-4\n",
    "config.batch_size = 256\n",
    "config.steps_per_epoch = 654 # 654\n",
    "config.epochs = 50\n",
    "\n",
    "config.brain_encoder_config.in_channels = 269\n",
    "config.decode_timestamps = True\n",
    "\n",
    "# Sensor layout settings\n",
    "config.brain_encoder_config.layout_dim=3\n",
    "config.brain_encoder_config.layout_proj=False\n",
    "config.brain_encoder_config.layout_scaling=\"midpoint\"\n",
    "# Merger with spatial attn\n",
    "config.brain_encoder_config.merger=True\n",
    "config.brain_encoder_config.merger_emb_type='mlp'\n",
    "config.brain_encoder_config.merger_emb_dim=1024\n",
    "config.brain_encoder_config.merger_channels=269\n",
    "config.brain_encoder_config.merger_dropout=0.1  # Float\n",
    "config.brain_encoder_config.merger_conditional=={\n",
    "        \"study\": [],\n",
    "        # \"subject\": [],\n",
    "}\n",
    "config.brain_encoder_config.conditions={\n",
    "        \"study\": [],\n",
    "        # \"subject\": [],\n",
    "}\n",
    "config.brain_encoder_config.conditional_layers=False\n",
    "config.brain_encoder_config.conditional_layers_dim='input'  # input or hidden_dim\n",
    "\n",
    "# config.brain_clipping = 20\n",
    "\n",
    "# config.brain_encoder_config.hidden_dim = 1024\n",
    "# config.brain_encoder_config.initial_linear = 1024\n",
    "\n",
    "session = TrainingSessionV2(\n",
    "    config=config,\n",
    "    studies={study: \"audiotext\" for study in data_partition.keys()},\n",
    "    data_path=\"data\",\n",
    "    save_path=\"saves/phase3/combining/channel_merger_269_mlp_1024_midpoint_3D_dataset_head\",\n",
    "    clear_cache=False,\n",
    "    cache_name=\"/home/ubuntu/cache\",\n",
    "    download_studies=True,\n",
    ")\n",
    "\n",
    "\n",
    "# session = load_training_session(\n",
    "#     save_path=\"saves/phase3/objectives/baseline_gwilliams_latent_loss_no_latent_alignment/epoch_39\",\n",
    "#     studies={\"gwilliams2023\": \"audiotext\"},\n",
    "#     data_path=\"data\",\n",
    "#     cache_name=\"/home/ubuntu/cache\",\n",
    "# )\n",
    "\n",
    "try:\n",
    "    session.train(\n",
    "        device=\"cuda\",\n",
    "        buffer_size=30,\n",
    "        num_workers=(multiprocessing.cpu_count() - 2),\n",
    "        max_cache_size=800,\n",
    "        current_epoch=0,\n",
    "    )\n",
    "except KeyboardInterrupt as e:\n",
    "    print(\"Exited\")\n",
    "\n",
    "# try:\n",
    "#     session.pre_process_all_recordings(\n",
    "#         buffer_size=30, num_workers=multiprocessing.cpu_count() - 10, max_cache_size=800\n",
    "#     )\n",
    "# except KeyboardInterrupt as e:\n",
    "#     print(\"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gwilliams2023 with batch type audiotext\n",
      "Loading Armeini2022 with batch type audiotext\n",
      "Data partitioned on studies ['gwilliams2023', 'armeini2022'].\n",
      "Train: 159, Unseen Task: 51, Unseen Subject: 12, Unseen Both: 4.\n",
      "\n",
      "Conditional layer study initialized with 3 conditions\n",
      "RNNEncoder initialized as conformer with 4 layers, 256 d_model, 4 nhead\n",
      "\tEmbedding: sinusoidal, params: 6075392\n",
      "SimpleConv initialized with 10274922 parameters, cond: ['study']\n",
      "Merger True, merger channels 269\n",
      "ConvBlocks: 4, hidden_dim: 256, params 2626048\n",
      "Using torch.bfloat16\n",
      "Found 64 target modules for AdaLora: ['model.encoder.layers.0.self_attn.k_proj', 'model.encoder.layers.0.self_attn.v_proj', 'model.encoder.layers.0.self_attn.q_proj', 'model.encoder.layers.0.self_attn.out_proj', 'model.encoder.layers.0.fc1', 'model.encoder.layers.0.fc2', 'model.encoder.layers.1.self_attn.k_proj', 'model.encoder.layers.1.self_attn.v_proj', 'model.encoder.layers.1.self_attn.q_proj', 'model.encoder.layers.1.self_attn.out_proj', 'model.encoder.layers.1.fc1', 'model.encoder.layers.1.fc2', 'model.encoder.layers.2.self_attn.k_proj', 'model.encoder.layers.2.self_attn.v_proj', 'model.encoder.layers.2.self_attn.q_proj', 'model.encoder.layers.2.self_attn.out_proj', 'model.encoder.layers.2.fc1', 'model.encoder.layers.2.fc2', 'model.encoder.layers.3.self_attn.k_proj', 'model.encoder.layers.3.self_attn.v_proj', 'model.encoder.layers.3.self_attn.q_proj', 'model.encoder.layers.3.self_attn.out_proj', 'model.encoder.layers.3.fc1', 'model.encoder.layers.3.fc2', 'model.decoder.layers.0.self_attn.k_proj', 'model.decoder.layers.0.self_attn.v_proj', 'model.decoder.layers.0.self_attn.q_proj', 'model.decoder.layers.0.self_attn.out_proj', 'model.decoder.layers.0.encoder_attn.k_proj', 'model.decoder.layers.0.encoder_attn.v_proj', 'model.decoder.layers.0.encoder_attn.q_proj', 'model.decoder.layers.0.encoder_attn.out_proj', 'model.decoder.layers.0.fc1', 'model.decoder.layers.0.fc2', 'model.decoder.layers.1.self_attn.k_proj', 'model.decoder.layers.1.self_attn.v_proj', 'model.decoder.layers.1.self_attn.q_proj', 'model.decoder.layers.1.self_attn.out_proj', 'model.decoder.layers.1.encoder_attn.k_proj', 'model.decoder.layers.1.encoder_attn.v_proj', 'model.decoder.layers.1.encoder_attn.q_proj', 'model.decoder.layers.1.encoder_attn.out_proj', 'model.decoder.layers.1.fc1', 'model.decoder.layers.1.fc2', 'model.decoder.layers.2.self_attn.k_proj', 'model.decoder.layers.2.self_attn.v_proj', 'model.decoder.layers.2.self_attn.q_proj', 'model.decoder.layers.2.self_attn.out_proj', 'model.decoder.layers.2.encoder_attn.k_proj', 'model.decoder.layers.2.encoder_attn.v_proj', 'model.decoder.layers.2.encoder_attn.q_proj', 'model.decoder.layers.2.encoder_attn.out_proj', 'model.decoder.layers.2.fc1', 'model.decoder.layers.2.fc2', 'model.decoder.layers.3.self_attn.k_proj', 'model.decoder.layers.3.self_attn.v_proj', 'model.decoder.layers.3.self_attn.q_proj', 'model.decoder.layers.3.self_attn.out_proj', 'model.decoder.layers.3.encoder_attn.k_proj', 'model.decoder.layers.3.encoder_attn.v_proj', 'model.decoder.layers.3.encoder_attn.q_proj', 'model.decoder.layers.3.encoder_attn.out_proj', 'model.decoder.layers.3.fc1', 'model.decoder.layers.3.fc2']\n",
      "openai/whisper-tiny.en loaded with total params = 38572096. 811776 are trainable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 159/159 [19:37<00:00,  7.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 5.41m.\n",
      "Epoch 1 done in 25.03m. 0.16m/recording.\n",
      "\n",
      "\n",
      "New best epoch 1 with CER 1.0483 and BLEU 0.0041.\n",
      "Mel Loss: 6.1477, Clip Loss: 9.5230, MSE: 1.0847\n",
      "Mel accuracy: 0.0050, Top 5: 0.0227, Top 10: 0.0448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 159/159 [19:19<00:00,  7.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.30m.\n",
      "Epoch 2 done in 23.64m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 2 with CER 0.9207 and BLEU 0.0134.\n",
      "Mel Loss: 5.8755, Clip Loss: 9.5190, MSE: 0.4101\n",
      "Mel accuracy: 0.0046, Top 5: 0.0224, Top 10: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 159/159 [19:18<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.19m.\n",
      "Epoch 3 done in 22.50m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:   0%|          | 0/159 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rank reallocation at recording 1962.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 159/159 [19:22<00:00,  7.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.44m.\n",
      "Epoch 4 done in 22.82m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 159/159 [19:18<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.67m.\n",
      "Epoch 5 done in 22.99m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 159/159 [19:32<00:00,  7.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.99m.\n",
      "Epoch 6 done in 23.53m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 159/159 [19:18<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.82m.\n",
      "Epoch 7 done in 23.12m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 159/159 [19:18<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.44m.\n",
      "Epoch 8 done in 23.76m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 159/159 [19:20<00:00,  7.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.68m.\n",
      "Epoch 9 done in 23.03m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 159/159 [19:24<00:00,  7.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.52m.\n",
      "Epoch 10 done in 22.93m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 10 with CER 0.9118 and BLEU 0.0059.\n",
      "Mel Loss: 5.8891, Clip Loss: 9.5480, MSE: 0.4007\n",
      "Mel accuracy: 0.0090, Top 5: 0.0394, Top 10: 0.0748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 159/159 [19:21<00:00,  7.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.19m.\n",
      "Epoch 11 done in 23.55m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 11 with CER 0.9211 and BLEU 0.0151.\n",
      "Mel Loss: 5.8966, Clip Loss: 9.5337, MSE: 0.4410\n",
      "Mel accuracy: 0.0085, Top 5: 0.0382, Top 10: 0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 159/159 [19:21<00:00,  7.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.89m.\n",
      "Epoch 12 done in 23.26m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 12 with CER 0.9128 and BLEU 0.0058.\n",
      "Mel Loss: 5.8907, Clip Loss: 9.5190, MSE: 0.4481\n",
      "Mel accuracy: 0.0147, Top 5: 0.0590, Top 10: 0.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 159/159 [19:17<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.15m.\n",
      "Epoch 13 done in 23.45m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 13 with CER 0.9219 and BLEU 0.0134.\n",
      "Mel Loss: 5.8840, Clip Loss: 9.5112, MSE: 0.4431\n",
      "Mel accuracy: 0.0267, Top 5: 0.0937, Top 10: 0.1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 159/159 [19:24<00:00,  7.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.79m.\n",
      "Epoch 14 done in 23.20m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 14 with CER 0.9054 and BLEU 0.0113.\n",
      "Mel Loss: 5.8993, Clip Loss: 9.5271, MSE: 0.4578\n",
      "Mel accuracy: 0.0354, Top 5: 0.1180, Top 10: 0.1913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 159/159 [19:24<00:00,  7.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.39m.\n",
      "Epoch 15 done in 23.80m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 15 with CER 0.9724 and BLEU 0.0145.\n",
      "Mel Loss: 5.8601, Clip Loss: 9.4667, MSE: 0.4501\n",
      "Mel accuracy: 0.0495, Top 5: 0.1567, Top 10: 0.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 159/159 [19:16<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.07m.\n",
      "Epoch 16 done in 23.36m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 16 with CER 0.9148 and BLEU 0.0104.\n",
      "Mel Loss: 5.8857, Clip Loss: 9.4773, MSE: 0.4982\n",
      "Mel accuracy: 0.0472, Top 5: 0.1529, Top 10: 0.2372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 159/159 [19:23<00:00,  7.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.78m.\n",
      "Epoch 17 done in 23.17m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 159/159 [19:23<00:00,  7.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.13m.\n",
      "Epoch 18 done in 23.53m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.      | 50/159 [06:21<11:29,  6.32s/it] \n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# del session.logger\n",
    "# del session.epoch_logger\n",
    "# del session\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "import multiprocessing\n",
    "from train.training_session_v2 import TrainingSessionV2, load_training_session\n",
    "from config import TrainingConfigV2\n",
    "from config import SimpleConvConfig\n",
    "\n",
    "data_partition = {\n",
    "    \"gwilliams2023\": {\n",
    "        \"testing_subjects\": [19, 20, 21],\n",
    "        \"testing_tasks\": [0],\n",
    "    },\n",
    "    \"armeini2022\": {\n",
    "        \"testing_subjects\": [],\n",
    "        \"testing_tasks\": [0, 1],\n",
    "    },\n",
    "}\n",
    "\n",
    "model_config = SimpleConvConfig(\n",
    "    # Str to list of possible conditions\n",
    "    mel_normalization=False,\n",
    "    conditions={\n",
    "        \"study\": [],\n",
    "        \"subject\": [],\n",
    "    },\n",
    "    # Channels\n",
    "    in_channels=208,\n",
    "    out_channels=80,\n",
    "    hidden_dim=256,\n",
    "    dropout=0.2,\n",
    "    initial_batch_norm=True,\n",
    "    # # Sensor layout settings\n",
    "    # layout_dim=2,\n",
    "    # layout_proj=True,\n",
    "    # layout_scaling=\"minmax\",\n",
    "    # # Merger with spatial attn\n",
    "    # merger=False,\n",
    "    # merger_emb_type=None,\n",
    "    # merger_emb_dim=0,\n",
    "    # merger_channels=0,\n",
    "    # merger_dropout=0.0,  # Float\n",
    "    # merger_conditional=None,\n",
    "    # Inital\n",
    "    initial_linear=256,\n",
    "    initial_depth=1,\n",
    "    # Conditional layers\n",
    "    conditional_layers=False,\n",
    "    conditional_layers_dim=None,  # input or hidden_dim\n",
    "    # Conv layer overall structure\n",
    "    depth=4,\n",
    "    kernel_size=3,\n",
    "    growth=1.0,\n",
    "    dilation_growth=2,\n",
    "    dilation_period=5,\n",
    "    glu=1,\n",
    "    conv_dropout=0.2,\n",
    "    dropout_input=0.1,\n",
    "    batch_norm=True,\n",
    "    half=True,\n",
    "    cnn_pos_encoding=False,\n",
    "    # Quantizer\n",
    "    quantizer=False,\n",
    "    num_codebooks=0,\n",
    "    codebook_size=0,\n",
    "    quantizer_commitment=0,\n",
    "    quantizer_temp_init=0,\n",
    "    quantizer_temp_min=0,\n",
    "    quantizer_temp_decay=0,\n",
    "    # Transformers Encoders\n",
    "    transformer_input=\"continuous\",\n",
    "    transformer_encoder_emb=\"sinusoidal\",\n",
    "    transformer_encoder_layers=4,\n",
    "    transformer_encoder_heads=4,\n",
    "    # Conformer encoder variant\n",
    "    rnn_type=\"conformer\",\n",
    "    depthwise_conv_kernel_size=15,\n",
    "    use_group_norm=False,\n",
    "    convolution_first=False,\n",
    "    # Transformer Decoders\n",
    "    transformer_decoder_emb=None,\n",
    "    transformer_decoder_layers=0,\n",
    "    transformer_decoder_heads=0,\n",
    "    transformer_decoder_dim=0,\n",
    ")\n",
    "\n",
    "config = TrainingConfigV2(\n",
    "    brain_encoder_config=model_config,\n",
    "    data_partition=data_partition,\n",
    "    # Ada lora settings\n",
    "    # Around 100k total batches an epoch for gwilliams\n",
    "    use_adalora=True,\n",
    "    adalora_init_r=12,\n",
    "    adalora_target_r=4,\n",
    "    adalora_tinit=(654 * 3),  # 5% total steps\n",
    "    adalora_tfinal=(654 * 8),  # 50-80% total steps\n",
    "    adalora_deltaT=(654 * 1),  # 1-5% total steps\n",
    "    adalora_lora_alpha=32,\n",
    "    adalora_lora_dropout=0.1,\n",
    "    adalora_total_step=(654 * 50),\n",
    "    # Pre-processing parameters\n",
    "    # Brain\n",
    "    new_freq=200,\n",
    "    frequency_bands={\"all\": (0.5, 80)},\n",
    "    max_random_shift=1.0,\n",
    "    window_size=4,\n",
    "    window_stride=1,\n",
    "    brain_clipping=None,\n",
    "    baseline_window=0.5,\n",
    "    notch_filter=True,\n",
    "    scaling=\"both\",\n",
    "    delay=0.15,\n",
    "    # Audio\n",
    "    audio_model=\"openai/whisper-tiny.en\",\n",
    "    # Hyperparameters\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=450, # 654,\n",
    "    batch_size=128,\n",
    "    random_test_size=10,\n",
    "    seed=42,\n",
    "    mel_alignment_objectives = {\n",
    "        \"clip_loss\": 0.6,\n",
    "        \"mse_loss\": 0.4\n",
    "    },\n",
    "    latent_alignment_objectives= {\n",
    "        \"cosine_similarity\": 0.4,\n",
    "        \"mse_loss\": 0.4,\n",
    "        \"clip_loss\": 0.6,\n",
    "        \"mmd_loss\": 0.0\n",
    "    },\n",
    "    decode_timestamps=True,\n",
    ")\n",
    "\n",
    "config.brain_encoder_config.mel_normalization = False\n",
    "config.learning_rate = 3e-4\n",
    "config.batch_size = 256\n",
    "config.steps_per_epoch = 654 # 654\n",
    "config.epochs = 50\n",
    "\n",
    "config.brain_encoder_config.in_channels = 269\n",
    "config.decode_timestamps = True\n",
    "\n",
    "# Sensor layout settings\n",
    "config.brain_encoder_config.layout_dim=3\n",
    "config.brain_encoder_config.layout_proj=False\n",
    "config.brain_encoder_config.layout_scaling=\"midpoint\"\n",
    "# Merger with spatial attn\n",
    "config.brain_encoder_config.merger=True\n",
    "config.brain_encoder_config.merger_emb_type='mlp'\n",
    "config.brain_encoder_config.merger_emb_dim=1024\n",
    "config.brain_encoder_config.merger_channels=269\n",
    "config.brain_encoder_config.merger_dropout=0.1  # Float\n",
    "config.brain_encoder_config.merger_conditional=={\n",
    "        \"study\": [],\n",
    "        # \"subject\": [],\n",
    "}\n",
    "config.brain_encoder_config.conditions={\n",
    "        \"study\": [],\n",
    "        # \"subject\": [],\n",
    "}\n",
    "config.brain_encoder_config.conditional_layers=True\n",
    "config.brain_encoder_config.conditional_layers_dim='input'  # input or hidden_dim\n",
    "\n",
    "# config.brain_clipping = 20\n",
    "\n",
    "# config.brain_encoder_config.hidden_dim = 1024\n",
    "# config.brain_encoder_config.initial_linear = 1024\n",
    "\n",
    "session = TrainingSessionV2(\n",
    "    config=config,\n",
    "    studies={study: \"audiotext\" for study in data_partition.keys()},\n",
    "    data_path=\"data\",\n",
    "    save_path=\"saves/phase3/combining/channel_merger_269_mlp_1024_midpoint_3D_dataset_head_and_layer\",\n",
    "    clear_cache=False,\n",
    "    cache_name=\"/home/ubuntu/cache\",\n",
    "    download_studies=True,\n",
    ")\n",
    "\n",
    "\n",
    "# session = load_training_session(\n",
    "#     save_path=\"saves/phase3/objectives/baseline_gwilliams_latent_loss_no_latent_alignment/epoch_39\",\n",
    "#     studies={\"gwilliams2023\": \"audiotext\"},\n",
    "#     data_path=\"data\",\n",
    "#     cache_name=\"/home/ubuntu/cache\",\n",
    "# )\n",
    "\n",
    "try:\n",
    "    session.train(\n",
    "        device=\"cuda\",\n",
    "        buffer_size=30,\n",
    "        num_workers=(multiprocessing.cpu_count() - 2),\n",
    "        max_cache_size=800,\n",
    "        current_epoch=0,\n",
    "    )\n",
    "except KeyboardInterrupt as e:\n",
    "    print(\"Exited\")\n",
    "\n",
    "# try:\n",
    "#     session.pre_process_all_recordings(\n",
    "#         buffer_size=30, num_workers=multiprocessing.cpu_count() - 10, max_cache_size=800\n",
    "#     )\n",
    "# except KeyboardInterrupt as e:\n",
    "#     print(\"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "brain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
