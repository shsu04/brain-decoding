{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "/home/ubuntu/storage-texas/data/armeini2022 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 149\u001b[39m\n\u001b[32m    145\u001b[39m config.steps_per_epoch = \u001b[32m450\u001b[39m\n\u001b[32m    147\u001b[39m config.decode_timestamps = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m session = \u001b[43mTrainingSessionV2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstudies\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudiotext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_partition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/ubuntu/storage-texas/data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msaves/phase2/architecture/subject/vq_concat_input_4C_8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcache\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_studies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m#     session.train(\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;66;03m#         device=\"cuda\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# except KeyboardInterrupt as e:\u001b[39;00m\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m#     print(\"Exited\")\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/brain-decoding/train/training_session_v2.py:46\u001b[39m, in \u001b[36mTrainingSessionV2.__init__\u001b[39m\u001b[34m(self, config, studies, data_path, save_path, clear_cache, max_cache_size, cache_name, download_studies)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     37\u001b[39m     config: TrainingConfigV2 = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     download_studies: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     45\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstudies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclear_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_enabled\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_cache_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_cache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_studies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_studies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;66;03m# MODEL\u001b[39;00m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = WhisperDecoder(\n\u001b[32m     60\u001b[39m         brain_module_config=config.brain_encoder_config,\n\u001b[32m     61\u001b[39m         adalora_config=config.adalora_config,\n\u001b[32m     62\u001b[39m         audio_model_id=config.audio_model,\n\u001b[32m     63\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/brain-decoding/train/training_session.py:79\u001b[39m, in \u001b[36mTrainingSession.__init__\u001b[39m\u001b[34m(self, config, studies, data_path, save_path, clear_cache, cache_enabled, max_cache_size, cache_name, download_studies)\u001b[39m\n\u001b[32m     77\u001b[39m path = os.path.join(data_path, study)\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28mself\u001b[39m.studies[study] = \u001b[43mStudyFactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_study\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_enabled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_cache_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_cache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_studies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m clear_cache:\n\u001b[32m     89\u001b[39m         shutil.rmtree(\u001b[38;5;28mself\u001b[39m.studies[study].cache_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/brain-decoding/studies/study_factory.py:25\u001b[39m, in \u001b[36mStudyFactory.create_study\u001b[39m\u001b[34m(cls, study_name, batch_type, path, cache_enabled, max_cache_size, cache_name, download)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m study_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m STUDIES:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStudy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSTUDIES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_enabled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_cache_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_cache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/brain-decoding/studies/armeini2022.py:42\u001b[39m, in \u001b[36mArmeini2022.__init__\u001b[39m\u001b[34m(self, batch_type, path, cache_enabled, max_cache_size, cache_name, download)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m download_bool == \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     40\u001b[39m         \u001b[38;5;28mself\u001b[39m.download(root_dir)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m os.path.exists(root_dir), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mself\u001b[39m.root_dir = root_dir\n\u001b[32m     45\u001b[39m \u001b[38;5;28mself\u001b[39m.cache_dir = os.path.join(os.getcwd(), cache_name, \u001b[33m\"\u001b[39m\u001b[33marmeini2022\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAssertionError\u001b[39m: /home/ubuntu/storage-texas/data/armeini2022 does not exist"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# del session.logger\n",
    "# del session.epoch_logger\n",
    "# del session\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "import multiprocessing\n",
    "from train.training_session_v2 import TrainingSessionV2\n",
    "from config import TrainingConfigV2\n",
    "from config import SimpleConvConfig\n",
    "\n",
    "data_partition = {\n",
    "    # \"gwilliams2023\": {\n",
    "    #     \"testing_subjects\": [19, 20, 21],\n",
    "    #     \"testing_tasks\": [0],\n",
    "    # },\n",
    "    \"armeini2022\": {\n",
    "        \"testing_subjects\": [],\n",
    "        \"testing_tasks\": [8, 9],\n",
    "    },\n",
    "}\n",
    "\n",
    "model_config = SimpleConvConfig(\n",
    "    # Str to list of possible conditions\n",
    "    mel_normalization=False,\n",
    "    conditions={\n",
    "        \"study\": [],\n",
    "        \"subject\": [],\n",
    "    },\n",
    "    # Channels\n",
    "    in_channels=208,\n",
    "    out_channels=80,\n",
    "    hidden_dim=256,\n",
    "    dropout=0.2,\n",
    "    initial_batch_norm=True,\n",
    "    # Sensor layout settings\n",
    "    layout_dim=2,\n",
    "    layout_proj=True,\n",
    "    layout_scaling=\"minmax\",\n",
    "    # Merger with spatial attn\n",
    "    merger=False,\n",
    "    merger_emb_type=None,\n",
    "    merger_emb_dim=0,\n",
    "    merger_channels=0,\n",
    "    merger_dropout=0.0,  # Float\n",
    "    merger_conditional=None,\n",
    "    # Inital\n",
    "    initial_linear=256,\n",
    "    initial_depth=1,\n",
    "    # Conditional layers\n",
    "    conditional_layers=False,\n",
    "    conditional_layers_dim=None,  # input or hidden_dim\n",
    "    # Conv layer overall structure\n",
    "    depth=4,\n",
    "    kernel_size=3,\n",
    "    growth=1.0,\n",
    "    dilation_growth=2,\n",
    "    dilation_period=5,\n",
    "    glu=1,\n",
    "    conv_dropout=0.2,\n",
    "    dropout_input=0.1,\n",
    "    batch_norm=True,\n",
    "    half=True,\n",
    "    cnn_pos_encoding=False,\n",
    "    # Quantizer\n",
    "    quantizer=False,\n",
    "    num_codebooks=0,\n",
    "    codebook_size=0,\n",
    "    quantizer_commitment=0,\n",
    "    quantizer_temp_init=0,\n",
    "    quantizer_temp_min=0,\n",
    "    quantizer_temp_decay=0,\n",
    "    # Transformers Encoders\n",
    "    transformer_input=\"continuous\",\n",
    "    transformer_encoder_emb=\"sinusoidal\",\n",
    "    transformer_encoder_layers=4,\n",
    "    transformer_encoder_heads=4,\n",
    "    # Conformer encoder variant\n",
    "    rnn_type=\"conformer\",\n",
    "    depthwise_conv_kernel_size=15,\n",
    "    use_group_norm=False,\n",
    "    convolution_first=False,\n",
    "    # Transformer Decoders\n",
    "    transformer_decoder_emb=None,\n",
    "    transformer_decoder_layers=0,\n",
    "    transformer_decoder_heads=0,\n",
    "    transformer_decoder_dim=0,\n",
    ")\n",
    "\n",
    "config = TrainingConfigV2(\n",
    "    brain_encoder_config=model_config,\n",
    "    data_partition=data_partition,\n",
    "    # Ada lora settings\n",
    "    # Around 100k total batches an epoch for gwilliams\n",
    "    adalora_init_r=12,\n",
    "    adalora_target_r=4,\n",
    "    adalora_tinit=(450 * 3),  # 5% total steps\n",
    "    adalora_tfinal=(450 * 8),  # 50-80% total steps\n",
    "    adalora_deltaT=(450 * 1),  # 1-5% total steps\n",
    "    adalora_lora_alpha=32,\n",
    "    adalora_lora_dropout=0.1,\n",
    "    adalora_total_step=(450 * 50),\n",
    "    # Pre-processing parameters\n",
    "    # Brain\n",
    "    new_freq=200,\n",
    "    frequency_bands={\"all\": (0.5, 80)},\n",
    "    max_random_shift=1.0,\n",
    "    window_size=4,\n",
    "    window_stride=1,\n",
    "    brain_clipping=None,\n",
    "    baseline_window=0.5,\n",
    "    notch_filter=True,\n",
    "    scaling=\"both\",\n",
    "    delay=0.15,\n",
    "    # Audio\n",
    "    audio_model=\"openai/whisper-tiny.en\",\n",
    "    # Hyperparameters\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=450,\n",
    "    batch_size=128,\n",
    "    random_test_size=10,\n",
    "    seed=42,\n",
    "    mel_alignment_objectives={\n",
    "        \"clip_loss\": 0.6,\n",
    "        \"mse_loss\": 0.4,\n",
    "    },\n",
    "    latent_alignment_objectives={\n",
    "        \"cosine_similarity\": 0.4,\n",
    "        \"mse_loss\": 0.4,\n",
    "        \"clip_loss\": 0.2,\n",
    "        \"mmd_loss\": 0.0,\n",
    "    },\n",
    "    decode_timestamps=True,\n",
    ")\n",
    "\n",
    "config.brain_encoder_config.mel_normalization = False\n",
    "config.learning_rate = 3e-4\n",
    "config.batch_size = 256\n",
    "config.steps_per_epoch = 450\n",
    "\n",
    "config.decode_timestamps = True\n",
    "\n",
    "session = TrainingSessionV2(\n",
    "    config=config,\n",
    "    studies={study: \"audiotext\" for study in data_partition.keys()},\n",
    "    data_path=\"/home/ubuntu/storage-texas/data\",\n",
    "    save_path=\"saves/phase2/architecture/subject/vq_concat_input_4C_8\",\n",
    "    clear_cache=False,\n",
    "    cache_name=\"cache\",\n",
    "    download_studies=True,\n",
    ")\n",
    "\n",
    "# try:\n",
    "#     session.train(\n",
    "#         device=\"cuda\",\n",
    "#         buffer_size=30,\n",
    "#         num_workers=(multiprocessing.cpu_count() - 2),\n",
    "#         max_cache_size=400,\n",
    "#         current_epoch=0,\n",
    "#     )\n",
    "# except KeyboardInterrupt as e:\n",
    "#     print(\"Exited\")\n",
    "\n",
    "# try:\n",
    "#     session.pre_process_all_recordings(\n",
    "#         buffer_size=30, num_workers=multiprocessing.cpu_count() - 2, max_cache_size=400\n",
    "#     )\n",
    "# except KeyboardInterrupt as e:\n",
    "#     print(\"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
