{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gwilliams2023 with batch type audiotext\n",
      "Loading Armeini2022 with batch type audiotext\n",
      "Data partitioned on studies ['gwilliams2023', 'armeini2022'].\n",
      "Train: 159, Unseen Task: 51, Unseen Subject: 12, Unseen Both: 4.\n",
      "\n",
      "RNNEncoder initialized as conformer with 4 layers, 256 d_model, 4 nhead\n",
      "\tEmbedding: sinusoidal, params: 6075392\n",
      "SimpleConv initialized with 9079658 parameters, cond: ['study', 'subject']\n",
      "Merger True, merger channels 269\n",
      "ConvBlocks: 4, hidden_dim: 256, params 2626048\n",
      "Using torch.bfloat16\n",
      "Found 64 target modules for AdaLora: ['model.encoder.layers.0.self_attn.k_proj', 'model.encoder.layers.0.self_attn.v_proj', 'model.encoder.layers.0.self_attn.q_proj', 'model.encoder.layers.0.self_attn.out_proj', 'model.encoder.layers.0.fc1', 'model.encoder.layers.0.fc2', 'model.encoder.layers.1.self_attn.k_proj', 'model.encoder.layers.1.self_attn.v_proj', 'model.encoder.layers.1.self_attn.q_proj', 'model.encoder.layers.1.self_attn.out_proj', 'model.encoder.layers.1.fc1', 'model.encoder.layers.1.fc2', 'model.encoder.layers.2.self_attn.k_proj', 'model.encoder.layers.2.self_attn.v_proj', 'model.encoder.layers.2.self_attn.q_proj', 'model.encoder.layers.2.self_attn.out_proj', 'model.encoder.layers.2.fc1', 'model.encoder.layers.2.fc2', 'model.encoder.layers.3.self_attn.k_proj', 'model.encoder.layers.3.self_attn.v_proj', 'model.encoder.layers.3.self_attn.q_proj', 'model.encoder.layers.3.self_attn.out_proj', 'model.encoder.layers.3.fc1', 'model.encoder.layers.3.fc2', 'model.decoder.layers.0.self_attn.k_proj', 'model.decoder.layers.0.self_attn.v_proj', 'model.decoder.layers.0.self_attn.q_proj', 'model.decoder.layers.0.self_attn.out_proj', 'model.decoder.layers.0.encoder_attn.k_proj', 'model.decoder.layers.0.encoder_attn.v_proj', 'model.decoder.layers.0.encoder_attn.q_proj', 'model.decoder.layers.0.encoder_attn.out_proj', 'model.decoder.layers.0.fc1', 'model.decoder.layers.0.fc2', 'model.decoder.layers.1.self_attn.k_proj', 'model.decoder.layers.1.self_attn.v_proj', 'model.decoder.layers.1.self_attn.q_proj', 'model.decoder.layers.1.self_attn.out_proj', 'model.decoder.layers.1.encoder_attn.k_proj', 'model.decoder.layers.1.encoder_attn.v_proj', 'model.decoder.layers.1.encoder_attn.q_proj', 'model.decoder.layers.1.encoder_attn.out_proj', 'model.decoder.layers.1.fc1', 'model.decoder.layers.1.fc2', 'model.decoder.layers.2.self_attn.k_proj', 'model.decoder.layers.2.self_attn.v_proj', 'model.decoder.layers.2.self_attn.q_proj', 'model.decoder.layers.2.self_attn.out_proj', 'model.decoder.layers.2.encoder_attn.k_proj', 'model.decoder.layers.2.encoder_attn.v_proj', 'model.decoder.layers.2.encoder_attn.q_proj', 'model.decoder.layers.2.encoder_attn.out_proj', 'model.decoder.layers.2.fc1', 'model.decoder.layers.2.fc2', 'model.decoder.layers.3.self_attn.k_proj', 'model.decoder.layers.3.self_attn.v_proj', 'model.decoder.layers.3.self_attn.q_proj', 'model.decoder.layers.3.self_attn.out_proj', 'model.decoder.layers.3.encoder_attn.k_proj', 'model.decoder.layers.3.encoder_attn.v_proj', 'model.decoder.layers.3.encoder_attn.q_proj', 'model.decoder.layers.3.encoder_attn.out_proj', 'model.decoder.layers.3.fc1', 'model.decoder.layers.3.fc2']\n",
      "openai/whisper-tiny.en loaded with total params = 38572096. 811776 are trainable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 15:56:10,297\tINFO worker.py:1841 -- Started a local Ray instance.\n",
      "Training Epoch 1: 100%|██████████| 159/159 [18:37<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.54m.\n",
      "Epoch 1 done in 23.21m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 1 with CER 0.9581 and BLEU 0.0047.\n",
      "Mel Loss: 6.2077, Clip Loss: 9.5250, MSE: 1.2316\n",
      "Mel accuracy: 0.0042, Top 5: 0.0226, Top 10: 0.0452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 26412 MiB, 27 objects, write throughput 780 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "Training Epoch 2: 100%|██████████| 159/159 [18:29<00:00,  6.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.82m.\n",
      "Epoch 2 done in 22.32m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 2 with CER 0.9536 and BLEU 0.0015.\n",
      "Mel Loss: 5.8794, Clip Loss: 9.5309, MSE: 0.4023\n",
      "Mel accuracy: 0.0046, Top 5: 0.0230, Top 10: 0.0458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 53842 MiB, 54 objects, write throughput 781 MiB/s.\n",
      "Training Epoch 3: 100%|██████████| 159/159 [18:31<00:00,  6.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.32m.\n",
      "Epoch 3 done in 21.85m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 3 with CER 0.9456 and BLEU 0.0016.\n",
      "Mel Loss: 5.8035, Clip Loss: 9.5177, MSE: 0.2323\n",
      "Mel accuracy: 0.0046, Top 5: 0.0226, Top 10: 0.0450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:   0%|          | 0/159 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rank reallocation at recording 1962.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 55867 MiB, 55 objects, write throughput 783 MiB/s.\n",
      "\u001b[36m(raylet)\u001b[0m Spilled 80308 MiB, 82 objects, write throughput 850 MiB/s.\n",
      "Training Epoch 4: 100%|██████████| 159/159 [18:37<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 1.17m.\n",
      "Epoch 4 done in 19.79m. 0.12m/recording.\n",
      "\n",
      "\n",
      "New best epoch 4 with CER 0.0000 and BLEU 0.0000.\n",
      "Mel Loss: 5.7935, Clip Loss: 9.5140, MSE: 0.2127\n",
      "Mel accuracy: 0.0044, Top 5: 0.0228, Top 10: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 159/159 [18:39<00:00,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 2.04m.\n",
      "Epoch 5 done in 20.71m. 0.13m/recording.\n",
      "\n",
      "\n",
      "New best epoch 5 with CER 0.8177 and BLEU 0.0083.\n",
      "Mel Loss: 5.8179, Clip Loss: 9.5538, MSE: 0.2142\n",
      "Mel accuracy: 0.0044, Top 5: 0.0223, Top 10: 0.0448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 159/159 [18:40<00:00,  7.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.66m.\n",
      "Epoch 6 done in 22.34m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 102205 MiB, 109 objects, write throughput 850 MiB/s.\n",
      "Training Epoch 7: 100%|██████████| 159/159 [18:42<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.09m.\n",
      "Epoch 7 done in 22.80m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 126956 MiB, 136 objects, write throughput 844 MiB/s.\n",
      "Training Epoch 8: 100%|██████████| 159/159 [18:39<00:00,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.74m.\n",
      "Epoch 8 done in 22.40m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 159/159 [18:32<00:00,  7.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.25m.\n",
      "Epoch 9 done in 22.80m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 159/159 [18:44<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.08m.\n",
      "Epoch 10 done in 21.82m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 159/159 [18:43<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.87m.\n",
      "Epoch 11 done in 22.60m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 159/159 [18:45<00:00,  7.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.77m.\n",
      "Epoch 12 done in 22.54m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 159/159 [18:42<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.99m.\n",
      "Epoch 13 done in 23.71m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 159/159 [18:36<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 5.20m.\n",
      "Epoch 14 done in 23.81m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 159/159 [18:44<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.87m.\n",
      "Epoch 15 done in 23.62m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 159/159 [18:37<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.98m.\n",
      "Epoch 16 done in 22.60m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 159/159 [18:49<00:00,  7.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.05m.\n",
      "Epoch 17 done in 22.89m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 151327 MiB, 163 objects, write throughput 841 MiB/s.\n",
      "Training Epoch 18: 100%|██████████| 159/159 [18:48<00:00,  7.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.98m.\n",
      "Epoch 18 done in 23.80m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 159/159 [18:46<00:00,  7.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 5.05m.\n",
      "Epoch 19 done in 23.84m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 159/159 [18:51<00:00,  7.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.91m.\n",
      "Epoch 20 done in 23.78m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 159/159 [18:52<00:00,  7.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 5.26m.\n",
      "Epoch 21 done in 24.14m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22: 100%|██████████| 159/159 [18:52<00:00,  7.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.32m.\n",
      "Epoch 22 done in 23.19m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 159/159 [19:39<00:00,  7.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.51m.\n",
      "Epoch 23 done in 24.18m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 159/159 [18:39<00:00,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.80m.\n",
      "Epoch 24 done in 23.45m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 159/159 [18:34<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.78m.\n",
      "Epoch 25 done in 23.35m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 159/159 [18:31<00:00,  6.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.49m.\n",
      "Epoch 26 done in 23.02m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27: 100%|██████████| 159/159 [18:33<00:00,  7.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.62m.\n",
      "Epoch 27 done in 23.17m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 275456 MiB, 294 objects, write throughput 846 MiB/s.\n",
      "Training Epoch 28: 100%|██████████| 159/159 [18:54<00:00,  7.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.70m.\n",
      "Epoch 28 done in 23.61m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 159/159 [18:48<00:00,  7.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 5.17m.\n",
      "Epoch 29 done in 23.98m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 159/159 [18:44<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.95m.\n",
      "Epoch 30 done in 23.69m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 159/159 [18:49<00:00,  7.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 5.29m.\n",
      "Epoch 31 done in 24.11m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32: 100%|██████████| 159/159 [18:41<00:00,  7.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.63m.\n",
      "Epoch 32 done in 23.32m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 159/159 [18:54<00:00,  7.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.59m.\n",
      "Epoch 33 done in 23.51m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 159/159 [18:47<00:00,  7.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.60m.\n",
      "Epoch 34 done in 23.39m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 159/159 [18:49<00:00,  7.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.53m.\n",
      "Epoch 35 done in 23.35m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 159/159 [18:51<00:00,  7.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.44m.\n",
      "Epoch 36 done in 23.30m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37: 100%|██████████| 159/159 [18:44<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.41m.\n",
      "Epoch 37 done in 23.16m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38: 100%|██████████| 159/159 [18:44<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.25m.\n",
      "Epoch 38 done in 23.00m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39: 100%|██████████| 159/159 [18:43<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.57m.\n",
      "Epoch 39 done in 23.30m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40: 100%|██████████| 159/159 [18:50<00:00,  7.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.68m.\n",
      "Epoch 40 done in 23.54m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41: 100%|██████████| 159/159 [18:47<00:00,  7.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.66m.\n",
      "Epoch 41 done in 23.46m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42: 100%|██████████| 159/159 [18:42<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.86m.\n",
      "Epoch 42 done in 23.56m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43: 100%|██████████| 159/159 [18:42<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.80m.\n",
      "Epoch 43 done in 23.51m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44: 100%|██████████| 159/159 [18:43<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.80m.\n",
      "Epoch 44 done in 23.53m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45: 100%|██████████| 159/159 [18:42<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.87m.\n",
      "Epoch 45 done in 23.58m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46: 100%|██████████| 159/159 [18:43<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.78m.\n",
      "Epoch 46 done in 23.51m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47: 100%|██████████| 159/159 [18:46<00:00,  7.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.50m.\n",
      "Epoch 47 done in 23.28m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 539367 MiB, 577 objects, write throughput 851 MiB/s.\n",
      "Training Epoch 48: 100%|██████████| 159/159 [18:46<00:00,  7.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.56m.\n",
      "Epoch 48 done in 23.34m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49: 100%|██████████| 159/159 [18:42<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.56m.\n",
      "Epoch 49 done in 23.27m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50: 100%|██████████| 159/159 [18:39<00:00,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.69m.\n",
      "Epoch 50 done in 23.35m. 0.15m/recording.\n",
      "\n",
      "\n",
      "Training completed. Highest epoch at 5.\n",
      "\n",
      "\n",
      "Test unseen_subject at epoch 5. Mel Loss: 5.7840, Clip Loss: 9.4633, MSE: 0.2650\n",
      "Mel accuracy: 0.0040, Top 5: 0.0230, Top 10: 0.0458\n",
      "BLEU: 0.0065, ROUGE-1: 0.0670, BERT: 0.3491, CER: 0.8161, SELF-BLEU: 0.4986\n",
      "\n",
      "\n",
      "Test unseen_task at epoch 5. Mel Loss: 5.7719, Clip Loss: 9.4537, MSE: 0.2492\n",
      "Mel accuracy: 0.0053, Top 5: 0.0249, Top 10: 0.0494\n",
      "BLEU: 0.0060, ROUGE-1: 0.0558, BERT: 0.3662, CER: 0.8124, SELF-BLEU: 0.4274\n",
      "\n",
      "\n",
      "Test unseen_both at epoch 5. Mel Loss: 5.7670, Clip Loss: 9.4447, MSE: 0.2505\n",
      "Mel accuracy: 0.0037, Top 5: 0.0209, Top 10: 0.0468\n",
      "BLEU: 0.0122, ROUGE-1: 0.1123, BERT: 0.3879, CER: 0.8247, SELF-BLEU: 0.5623\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# del session.logger\n",
    "# del session.epoch_logger\n",
    "# del session\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "import multiprocessing\n",
    "from train.training_session_v2 import TrainingSessionV2, load_training_session\n",
    "from config import TrainingConfigV2\n",
    "from config import SimpleConvConfig\n",
    "\n",
    "data_partition = {\n",
    "    \"gwilliams2023\": {\n",
    "        \"testing_subjects\": [19, 20, 21],\n",
    "        \"testing_tasks\": [0],\n",
    "    },\n",
    "    \"armeini2022\": {\n",
    "        \"testing_subjects\": [],\n",
    "        \"testing_tasks\": [0, 1],\n",
    "    },\n",
    "}\n",
    "\n",
    "model_config = SimpleConvConfig(\n",
    "    # Str to list of possible conditions\n",
    "    mel_normalization=False,\n",
    "    conditions={\n",
    "        \"study\": [],\n",
    "        \"subject\": [],\n",
    "    },\n",
    "    # Channels\n",
    "    in_channels=208,\n",
    "    out_channels=80,\n",
    "    hidden_dim=256,\n",
    "    dropout=0.2,\n",
    "    initial_batch_norm=True,\n",
    "    # # Sensor layout settings\n",
    "    # layout_dim=2,\n",
    "    # layout_proj=True,\n",
    "    # layout_scaling=\"minmax\",\n",
    "    # # Merger with spatial attn\n",
    "    # merger=False,\n",
    "    # merger_emb_type=None,\n",
    "    # merger_emb_dim=0,\n",
    "    # merger_channels=0,\n",
    "    # merger_dropout=0.0,  # Float\n",
    "    # merger_conditional=None,\n",
    "    # Inital\n",
    "    initial_linear=256,\n",
    "    initial_depth=1,\n",
    "    # Conditional layers\n",
    "    conditional_layers=False,\n",
    "    conditional_layers_dim=None,  # input or hidden_dim\n",
    "    # Conv layer overall structure\n",
    "    depth=4,\n",
    "    kernel_size=3,\n",
    "    growth=1.0,\n",
    "    dilation_growth=2,\n",
    "    dilation_period=5,\n",
    "    glu=1,\n",
    "    conv_dropout=0.2,\n",
    "    dropout_input=0.1,\n",
    "    batch_norm=True,\n",
    "    half=True,\n",
    "    cnn_pos_encoding=False,\n",
    "    # Quantizer\n",
    "    quantizer=False,\n",
    "    num_codebooks=0,\n",
    "    codebook_size=0,\n",
    "    quantizer_commitment=0,\n",
    "    quantizer_temp_init=0,\n",
    "    quantizer_temp_min=0,\n",
    "    quantizer_temp_decay=0,\n",
    "    # Transformers Encoders\n",
    "    transformer_input=\"continuous\",\n",
    "    transformer_encoder_emb=\"sinusoidal\",\n",
    "    transformer_encoder_layers=4,\n",
    "    transformer_encoder_heads=4,\n",
    "    # Conformer encoder variant\n",
    "    rnn_type=\"conformer\",\n",
    "    depthwise_conv_kernel_size=15,\n",
    "    use_group_norm=False,\n",
    "    convolution_first=False,\n",
    "    # Transformer Decoders\n",
    "    transformer_decoder_emb=None,\n",
    "    transformer_decoder_layers=0,\n",
    "    transformer_decoder_heads=0,\n",
    "    transformer_decoder_dim=0,\n",
    ")\n",
    "\n",
    "config = TrainingConfigV2(\n",
    "    brain_encoder_config=model_config,\n",
    "    data_partition=data_partition,\n",
    "    # Ada lora settings\n",
    "    # Around 100k total batches an epoch for gwilliams\n",
    "    use_adalora=True,\n",
    "    adalora_init_r=12,\n",
    "    adalora_target_r=4,\n",
    "    adalora_tinit=(654 * 3),  # 5% total steps\n",
    "    adalora_tfinal=(654 * 8),  # 50-80% total steps\n",
    "    adalora_deltaT=(654 * 1),  # 1-5% total steps\n",
    "    adalora_lora_alpha=32,\n",
    "    adalora_lora_dropout=0.1,\n",
    "    adalora_total_step=(654 * 50),\n",
    "    # Pre-processing parameters\n",
    "    # Brain\n",
    "    new_freq=200,\n",
    "    frequency_bands={\"all\": (0.5, 80)},\n",
    "    max_random_shift=1.0,\n",
    "    window_size=4,\n",
    "    window_stride=1,\n",
    "    brain_clipping=None,\n",
    "    baseline_window=0.5,\n",
    "    notch_filter=True,\n",
    "    scaling=\"both\",\n",
    "    delay=0.15,\n",
    "    # Audio\n",
    "    audio_model=\"openai/whisper-tiny.en\",\n",
    "    # Hyperparameters\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=450, # 654,\n",
    "    batch_size=128,\n",
    "    random_test_size=10,\n",
    "    seed=42,\n",
    "    mel_alignment_objectives = {\n",
    "        \"clip_loss\": 0.6,\n",
    "        \"mse_loss\": 0.4\n",
    "    },\n",
    "    latent_alignment_objectives= {\n",
    "        \"cosine_similarity\": 0.4,\n",
    "        \"mse_loss\": 0.4,\n",
    "        \"clip_loss\": 0.6,\n",
    "        \"mmd_loss\": 0.0\n",
    "    },\n",
    "    decode_timestamps=True,\n",
    ")\n",
    "\n",
    "config.brain_encoder_config.mel_normalization = False\n",
    "config.learning_rate = 3e-4\n",
    "config.batch_size = 256\n",
    "config.steps_per_epoch = 654 # 654\n",
    "config.epochs = 50\n",
    "\n",
    "config.brain_encoder_config.in_channels = 269\n",
    "config.decode_timestamps = True\n",
    "\n",
    "# Sensor layout settings\n",
    "config.brain_encoder_config.layout_dim=2\n",
    "config.brain_encoder_config.layout_proj=False\n",
    "config.brain_encoder_config.layout_scaling=\"midpoint\"\n",
    "# Merger with spatial attn\n",
    "config.brain_encoder_config.merger=True\n",
    "config.brain_encoder_config.merger_emb_type='mlp'\n",
    "config.brain_encoder_config.merger_emb_dim=256\n",
    "config.brain_encoder_config.merger_channels=269\n",
    "config.brain_encoder_config.merger_dropout=0.1  # Float\n",
    "config.brain_encoder_config.merger_conditional=None\n",
    "\n",
    "# config.brain_clipping = 20\n",
    "\n",
    "# config.brain_encoder_config.hidden_dim = 1024\n",
    "# config.brain_encoder_config.initial_linear = 1024\n",
    "\n",
    "session = TrainingSessionV2(\n",
    "    config=config,\n",
    "    studies={study: \"audiotext\" for study in data_partition.keys()},\n",
    "    data_path=\"data\",\n",
    "    save_path=\"saves/phase3/combining/channel_merger_269_mlp_256_midpoint_2d\",\n",
    "    clear_cache=False,\n",
    "    cache_name=\"/home/ubuntu/cache\",\n",
    "    download_studies=True,\n",
    ")\n",
    "\n",
    "\n",
    "# session = load_training_session(\n",
    "#     save_path=\"saves/phase3/objectives/baseline_gwilliams_latent_loss_no_latent_alignment/epoch_39\",\n",
    "#     studies={\"gwilliams2023\": \"audiotext\"},\n",
    "#     data_path=\"data\",\n",
    "#     cache_name=\"/home/ubuntu/cache\",\n",
    "# )\n",
    "\n",
    "try:\n",
    "    session.train(\n",
    "        device=\"cuda\",\n",
    "        buffer_size=30,\n",
    "        num_workers=(multiprocessing.cpu_count() - 2),\n",
    "        max_cache_size=800,\n",
    "        current_epoch=0,\n",
    "    )\n",
    "except KeyboardInterrupt as e:\n",
    "    print(\"Exited\")\n",
    "\n",
    "# try:\n",
    "#     session.pre_process_all_recordings(\n",
    "#         buffer_size=30, num_workers=multiprocessing.cpu_count() - 10, max_cache_size=800\n",
    "#     )\n",
    "# except KeyboardInterrupt as e:\n",
    "#     print(\"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gwilliams2023 with batch type audiotext\n",
      "Loading Armeini2022 with batch type audiotext\n",
      "Data partitioned on studies ['gwilliams2023', 'armeini2022'].\n",
      "Train: 159, Unseen Task: 51, Unseen Subject: 12, Unseen Both: 4.\n",
      "\n",
      "RNNEncoder initialized as conformer with 4 layers, 256 d_model, 4 nhead\n",
      "\tEmbedding: sinusoidal, params: 6075392\n",
      "SimpleConv initialized with 9079914 parameters, cond: ['study', 'subject']\n",
      "Merger True, merger channels 269\n",
      "ConvBlocks: 4, hidden_dim: 256, params 2626048\n",
      "Using torch.bfloat16\n",
      "Found 64 target modules for AdaLora: ['model.encoder.layers.0.self_attn.k_proj', 'model.encoder.layers.0.self_attn.v_proj', 'model.encoder.layers.0.self_attn.q_proj', 'model.encoder.layers.0.self_attn.out_proj', 'model.encoder.layers.0.fc1', 'model.encoder.layers.0.fc2', 'model.encoder.layers.1.self_attn.k_proj', 'model.encoder.layers.1.self_attn.v_proj', 'model.encoder.layers.1.self_attn.q_proj', 'model.encoder.layers.1.self_attn.out_proj', 'model.encoder.layers.1.fc1', 'model.encoder.layers.1.fc2', 'model.encoder.layers.2.self_attn.k_proj', 'model.encoder.layers.2.self_attn.v_proj', 'model.encoder.layers.2.self_attn.q_proj', 'model.encoder.layers.2.self_attn.out_proj', 'model.encoder.layers.2.fc1', 'model.encoder.layers.2.fc2', 'model.encoder.layers.3.self_attn.k_proj', 'model.encoder.layers.3.self_attn.v_proj', 'model.encoder.layers.3.self_attn.q_proj', 'model.encoder.layers.3.self_attn.out_proj', 'model.encoder.layers.3.fc1', 'model.encoder.layers.3.fc2', 'model.decoder.layers.0.self_attn.k_proj', 'model.decoder.layers.0.self_attn.v_proj', 'model.decoder.layers.0.self_attn.q_proj', 'model.decoder.layers.0.self_attn.out_proj', 'model.decoder.layers.0.encoder_attn.k_proj', 'model.decoder.layers.0.encoder_attn.v_proj', 'model.decoder.layers.0.encoder_attn.q_proj', 'model.decoder.layers.0.encoder_attn.out_proj', 'model.decoder.layers.0.fc1', 'model.decoder.layers.0.fc2', 'model.decoder.layers.1.self_attn.k_proj', 'model.decoder.layers.1.self_attn.v_proj', 'model.decoder.layers.1.self_attn.q_proj', 'model.decoder.layers.1.self_attn.out_proj', 'model.decoder.layers.1.encoder_attn.k_proj', 'model.decoder.layers.1.encoder_attn.v_proj', 'model.decoder.layers.1.encoder_attn.q_proj', 'model.decoder.layers.1.encoder_attn.out_proj', 'model.decoder.layers.1.fc1', 'model.decoder.layers.1.fc2', 'model.decoder.layers.2.self_attn.k_proj', 'model.decoder.layers.2.self_attn.v_proj', 'model.decoder.layers.2.self_attn.q_proj', 'model.decoder.layers.2.self_attn.out_proj', 'model.decoder.layers.2.encoder_attn.k_proj', 'model.decoder.layers.2.encoder_attn.v_proj', 'model.decoder.layers.2.encoder_attn.q_proj', 'model.decoder.layers.2.encoder_attn.out_proj', 'model.decoder.layers.2.fc1', 'model.decoder.layers.2.fc2', 'model.decoder.layers.3.self_attn.k_proj', 'model.decoder.layers.3.self_attn.v_proj', 'model.decoder.layers.3.self_attn.q_proj', 'model.decoder.layers.3.self_attn.out_proj', 'model.decoder.layers.3.encoder_attn.k_proj', 'model.decoder.layers.3.encoder_attn.v_proj', 'model.decoder.layers.3.encoder_attn.q_proj', 'model.decoder.layers.3.encoder_attn.out_proj', 'model.decoder.layers.3.fc1', 'model.decoder.layers.3.fc2']\n",
      "openai/whisper-tiny.en loaded with total params = 38572096. 811776 are trainable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 159/159 [20:03<00:00,  7.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 8.21m.\n",
      "Epoch 1 done in 28.28m. 0.18m/recording.\n",
      "\n",
      "\n",
      "New best epoch 1 with CER 4.0195 and BLEU 0.0037.\n",
      "Mel Loss: 6.2299, Clip Loss: 9.5205, MSE: 1.2939\n",
      "Mel accuracy: 0.0043, Top 5: 0.0226, Top 10: 0.0448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 159/159 [19:14<00:00,  7.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 1.30m.\n",
      "Epoch 2 done in 20.54m. 0.13m/recording.\n",
      "\n",
      "\n",
      "New best epoch 2 with CER 0.0000 and BLEU 0.0000.\n",
      "Mel Loss: 5.8909, Clip Loss: 9.5206, MSE: 0.4463\n",
      "Mel accuracy: 0.0046, Top 5: 0.0226, Top 10: 0.0448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 159/159 [19:00<00:00,  7.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.50m.\n",
      "Epoch 3 done in 22.52m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 3 with CER 0.9459 and BLEU 0.0013.\n",
      "Mel Loss: 5.8144, Clip Loss: 9.5157, MSE: 0.2624\n",
      "Mel accuracy: 0.0045, Top 5: 0.0222, Top 10: 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:   0%|          | 0/159 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rank reallocation at recording 1962.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 159/159 [19:17<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.39m.\n",
      "Epoch 4 done in 22.69m. 0.14m/recording.\n",
      "\n",
      "\n",
      "New best epoch 4 with CER 0.9455 and BLEU 0.0016.\n",
      "Mel Loss: 5.8038, Clip Loss: 9.5304, MSE: 0.2138\n",
      "Mel accuracy: 0.0047, Top 5: 0.0224, Top 10: 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 159/159 [19:17<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.01m.\n",
      "Epoch 5 done in 23.30m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 159/159 [19:18<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.51m.\n",
      "Epoch 6 done in 23.82m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 6 with CER 0.9421 and BLEU 0.0043.\n",
      "Mel Loss: 5.8590, Clip Loss: 9.5693, MSE: 0.2937\n",
      "Mel accuracy: 0.0110, Top 5: 0.0454, Top 10: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 159/159 [19:21<00:00,  7.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.63m.\n",
      "Epoch 7 done in 22.99m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 159/159 [19:06<00:00,  7.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.83m.\n",
      "Epoch 8 done in 22.94m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 159/159 [19:16<00:00,  7.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.93m.\n",
      "Epoch 9 done in 23.21m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 159/159 [19:33<00:00,  7.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.88m.\n",
      "Epoch 10 done in 23.44m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 159/159 [19:33<00:00,  7.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.44m.\n",
      "Epoch 11 done in 23.00m. 0.14m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 159/159 [19:34<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.44m.\n",
      "Epoch 12 done in 24.01m. 0.15m/recording.\n",
      "\n",
      "\n",
      "New best epoch 12 with CER 0.9345 and BLEU 0.0045.\n",
      "Mel Loss: 5.9132, Clip Loss: 9.5278, MSE: 0.4913\n",
      "Mel accuracy: 0.0460, Top 5: 0.1475, Top 10: 0.2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 159/159 [19:36<00:00,  7.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.50m.\n",
      "Epoch 13 done in 24.11m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 159/159 [19:36<00:00,  7.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.90m.\n",
      "Epoch 14 done in 23.51m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 159/159 [19:34<00:00,  7.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.08m.\n",
      "Epoch 15 done in 23.65m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 159/159 [19:36<00:00,  7.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.81m.\n",
      "Epoch 16 done in 23.41m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 159/159 [19:35<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.10m.\n",
      "Epoch 17 done in 23.69m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 159/159 [19:37<00:00,  7.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.23m.\n",
      "Epoch 18 done in 23.86m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 159/159 [19:33<00:00,  7.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 3.90m.\n",
      "Epoch 19 done in 23.47m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 159/159 [19:40<00:00,  7.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.02m.\n",
      "Epoch 20 done in 23.70m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 159/159 [19:36<00:00,  7.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.10m.\n",
      "Epoch 21 done in 23.71m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22: 100%|██████████| 159/159 [19:36<00:00,  7.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.21m.\n",
      "Epoch 22 done in 23.82m. 0.15m/recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 159/159 [19:38<00:00,  7.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done in 4.25m.\n",
      "Epoch 23 done in 23.89m. 0.15m/recording.\n",
      "Early stopping at epoch 23. Highest metrics at epoch 12.\n",
      "\n",
      "\n",
      "Training completed. Highest epoch at 12.\n",
      "\n",
      "\n",
      "Test unseen_subject at epoch 12. Mel Loss: 5.8548, Clip Loss: 9.4214, MSE: 0.5047\n",
      "Mel accuracy: 0.0463, Top 5: 0.1432, Top 10: 0.2430\n",
      "BLEU: 0.0069, ROUGE-1: 0.0478, BERT: 0.3626, CER: 0.9433, SELF-BLEU: 0.5101\n",
      "\n",
      "\n",
      "Test unseen_task at epoch 12. Mel Loss: 5.8786, Clip Loss: 9.4680, MSE: 0.4946\n",
      "Mel accuracy: 0.0431, Top 5: 0.1208, Top 10: 0.1947\n",
      "BLEU: 0.0034, ROUGE-1: 0.0260, BERT: 0.3591, CER: 0.9345, SELF-BLEU: 0.4907\n",
      "\n",
      "\n",
      "Test unseen_both at epoch 12. Mel Loss: 5.8590, Clip Loss: 9.4356, MSE: 0.4940\n",
      "Mel accuracy: 0.0505, Top 5: 0.1256, Top 10: 0.2488\n",
      "BLEU: 0.0033, ROUGE-1: 0.0220, BERT: 0.3571, CER: 0.9256, SELF-BLEU: 0.5224\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# del session.logger\n",
    "# del session.epoch_logger\n",
    "# del session\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "import multiprocessing\n",
    "from train.training_session_v2 import TrainingSessionV2, load_training_session\n",
    "from config import TrainingConfigV2\n",
    "from config import SimpleConvConfig\n",
    "\n",
    "data_partition = {\n",
    "    \"gwilliams2023\": {\n",
    "        \"testing_subjects\": [19, 20, 21],\n",
    "        \"testing_tasks\": [0],\n",
    "    },\n",
    "    \"armeini2022\": {\n",
    "        \"testing_subjects\": [],\n",
    "        \"testing_tasks\": [0, 1],\n",
    "    },\n",
    "}\n",
    "\n",
    "model_config = SimpleConvConfig(\n",
    "    # Str to list of possible conditions\n",
    "    mel_normalization=False,\n",
    "    conditions={\n",
    "        \"study\": [],\n",
    "        \"subject\": [],\n",
    "    },\n",
    "    # Channels\n",
    "    in_channels=208,\n",
    "    out_channels=80,\n",
    "    hidden_dim=256,\n",
    "    dropout=0.2,\n",
    "    initial_batch_norm=True,\n",
    "    # # Sensor layout settings\n",
    "    # layout_dim=2,\n",
    "    # layout_proj=True,\n",
    "    # layout_scaling=\"minmax\",\n",
    "    # # Merger with spatial attn\n",
    "    # merger=False,\n",
    "    # merger_emb_type=None,\n",
    "    # merger_emb_dim=0,\n",
    "    # merger_channels=0,\n",
    "    # merger_dropout=0.0,  # Float\n",
    "    # merger_conditional=None,\n",
    "    # Inital\n",
    "    initial_linear=256,\n",
    "    initial_depth=1,\n",
    "    # Conditional layers\n",
    "    conditional_layers=False,\n",
    "    conditional_layers_dim=None,  # input or hidden_dim\n",
    "    # Conv layer overall structure\n",
    "    depth=4,\n",
    "    kernel_size=3,\n",
    "    growth=1.0,\n",
    "    dilation_growth=2,\n",
    "    dilation_period=5,\n",
    "    glu=1,\n",
    "    conv_dropout=0.2,\n",
    "    dropout_input=0.1,\n",
    "    batch_norm=True,\n",
    "    half=True,\n",
    "    cnn_pos_encoding=False,\n",
    "    # Quantizer\n",
    "    quantizer=False,\n",
    "    num_codebooks=0,\n",
    "    codebook_size=0,\n",
    "    quantizer_commitment=0,\n",
    "    quantizer_temp_init=0,\n",
    "    quantizer_temp_min=0,\n",
    "    quantizer_temp_decay=0,\n",
    "    # Transformers Encoders\n",
    "    transformer_input=\"continuous\",\n",
    "    transformer_encoder_emb=\"sinusoidal\",\n",
    "    transformer_encoder_layers=4,\n",
    "    transformer_encoder_heads=4,\n",
    "    # Conformer encoder variant\n",
    "    rnn_type=\"conformer\",\n",
    "    depthwise_conv_kernel_size=15,\n",
    "    use_group_norm=False,\n",
    "    convolution_first=False,\n",
    "    # Transformer Decoders\n",
    "    transformer_decoder_emb=None,\n",
    "    transformer_decoder_layers=0,\n",
    "    transformer_decoder_heads=0,\n",
    "    transformer_decoder_dim=0,\n",
    ")\n",
    "\n",
    "config = TrainingConfigV2(\n",
    "    brain_encoder_config=model_config,\n",
    "    data_partition=data_partition,\n",
    "    # Ada lora settings\n",
    "    # Around 100k total batches an epoch for gwilliams\n",
    "    use_adalora=True,\n",
    "    adalora_init_r=12,\n",
    "    adalora_target_r=4,\n",
    "    adalora_tinit=(654 * 3),  # 5% total steps\n",
    "    adalora_tfinal=(654 * 8),  # 50-80% total steps\n",
    "    adalora_deltaT=(654 * 1),  # 1-5% total steps\n",
    "    adalora_lora_alpha=32,\n",
    "    adalora_lora_dropout=0.1,\n",
    "    adalora_total_step=(654 * 50),\n",
    "    # Pre-processing parameters\n",
    "    # Brain\n",
    "    new_freq=200,\n",
    "    frequency_bands={\"all\": (0.5, 80)},\n",
    "    max_random_shift=1.0,\n",
    "    window_size=4,\n",
    "    window_stride=1,\n",
    "    brain_clipping=None,\n",
    "    baseline_window=0.5,\n",
    "    notch_filter=True,\n",
    "    scaling=\"both\",\n",
    "    delay=0.15,\n",
    "    # Audio\n",
    "    audio_model=\"openai/whisper-tiny.en\",\n",
    "    # Hyperparameters\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=450, # 654,\n",
    "    batch_size=128,\n",
    "    random_test_size=10,\n",
    "    seed=42,\n",
    "    mel_alignment_objectives = {\n",
    "        \"clip_loss\": 0.6,\n",
    "        \"mse_loss\": 0.4\n",
    "    },\n",
    "    latent_alignment_objectives= {\n",
    "        \"cosine_similarity\": 0.4,\n",
    "        \"mse_loss\": 0.4,\n",
    "        \"clip_loss\": 0.6,\n",
    "        \"mmd_loss\": 0.0\n",
    "    },\n",
    "    decode_timestamps=True,\n",
    ")\n",
    "\n",
    "config.brain_encoder_config.mel_normalization = False\n",
    "config.learning_rate = 3e-4\n",
    "config.batch_size = 256\n",
    "config.steps_per_epoch = 654 # 654\n",
    "config.epochs = 50\n",
    "\n",
    "config.brain_encoder_config.in_channels = 269\n",
    "config.decode_timestamps = True\n",
    "\n",
    "# Sensor layout settings\n",
    "config.brain_encoder_config.layout_dim=3\n",
    "config.brain_encoder_config.layout_proj=False\n",
    "config.brain_encoder_config.layout_scaling=\"midpoint\"\n",
    "# Merger with spatial attn\n",
    "config.brain_encoder_config.merger=True\n",
    "config.brain_encoder_config.merger_emb_type='mlp'\n",
    "config.brain_encoder_config.merger_emb_dim=256\n",
    "config.brain_encoder_config.merger_channels=269\n",
    "config.brain_encoder_config.merger_dropout=0.1  # Float\n",
    "config.brain_encoder_config.merger_conditional=None\n",
    "\n",
    "# config.brain_clipping = 20\n",
    "\n",
    "# config.brain_encoder_config.hidden_dim = 1024\n",
    "# config.brain_encoder_config.initial_linear = 1024\n",
    "\n",
    "session = TrainingSessionV2(\n",
    "    config=config,\n",
    "    studies={study: \"audiotext\" for study in data_partition.keys()},\n",
    "    data_path=\"data\",\n",
    "    save_path=\"saves/phase3/combining/channel_merger_269_mlp_256_midpoint_3d\",\n",
    "    clear_cache=False,\n",
    "    cache_name=\"/home/ubuntu/cache\",\n",
    "    download_studies=True,\n",
    ")\n",
    "\n",
    "\n",
    "# session = load_training_session(\n",
    "#     save_path=\"saves/phase3/objectives/baseline_gwilliams_latent_loss_no_latent_alignment/epoch_39\",\n",
    "#     studies={\"gwilliams2023\": \"audiotext\"},\n",
    "#     data_path=\"data\",\n",
    "#     cache_name=\"/home/ubuntu/cache\",\n",
    "# )\n",
    "\n",
    "try:\n",
    "    session.train(\n",
    "        device=\"cuda\",\n",
    "        buffer_size=30,\n",
    "        num_workers=(multiprocessing.cpu_count() - 2),\n",
    "        max_cache_size=800,\n",
    "        current_epoch=0,\n",
    "    )\n",
    "except KeyboardInterrupt as e:\n",
    "    print(\"Exited\")\n",
    "\n",
    "# try:\n",
    "#     session.pre_process_all_recordings(\n",
    "#         buffer_size=30, num_workers=multiprocessing.cpu_count() - 10, max_cache_size=800\n",
    "#     )\n",
    "# except KeyboardInterrupt as e:\n",
    "#     print(\"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "brain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
