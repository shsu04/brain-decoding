{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gwilliams2023 with batch type audio\n",
      "Data partitioned on studies ['gwilliams2023'].\n",
      "Train: 135, Unseen Task: 12, Unseen Subject: 45, Unseen Both: 4.\n",
      "\n",
      "SimpleConv initialized with 9295984 parameters, cond: ['study', 'subject']\n",
      "Merger False, merger channels 0\n",
      "ConvBlocks: 6, hidden_dim: 384, params 8858112\n",
      "Found 36 target modules for AdaLora: ['k_proj', 'q_proj', 'v_proj', 'out_proj', 'fc1', 'fc2']\n",
      "AdaLora model has 663984 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 02:08:50,995\tINFO worker.py:1841 -- Started a local Ray instance.\n",
      "Training Epoch 1: 100%|██████████| 135/135 [13:22<00:00,  5.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.4294, Mel Loss: 3.4055\n",
      "Clip Loss: 5.1532, MSE Loss: 0.7839, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0106, Top 5 Accuracy: 0.0491, Top 10 Accuracy: 0.0964\n",
      "Final Layer Clip Loss: 6.0129, Final Layer MSE Loss: 1.5149, Final Layer Cosine Similarity Loss: 0.5384, Final Layer Total Loss: 2.0239\n",
      "Test unseen_subject completed., Loss: 4.9074, Mel Loss: 3.2911\n",
      "Clip Loss: 5.0142, MSE Loss: 0.7064, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0108, Top 5 Accuracy: 0.0483, Top 10 Accuracy: 0.1000\n",
      "Final Layer Clip Loss: 5.2173, Final Layer MSE Loss: 1.1015, Final Layer Cosine Similarity Loss: 0.3306, Final Layer Total Loss: 1.6163\n",
      "Test unseen_task completed., Loss: 5.1463, Mel Loss: 3.5063\n",
      "Clip Loss: 5.3671, MSE Loss: 0.7151, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0077, Top 5 Accuracy: 0.0430, Top 10 Accuracy: 0.0884\n",
      "Final Layer Clip Loss: 5.2861, Final Layer MSE Loss: 1.1225, Final Layer Cosine Similarity Loss: 0.3345, Final Layer Total Loss: 1.6400\n",
      "Test unseen_both completed., Loss: 4.9185, Mel Loss: 3.3121\n",
      "Clip Loss: 5.0545, MSE Loss: 0.6985, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0148, Top 5 Accuracy: 0.0554, Top 10 Accuracy: 0.0948\n",
      "Final Layer Clip Loss: 5.1676, Final Layer MSE Loss: 1.1018, Final Layer Cosine Similarity Loss: 0.3306, Final Layer Total Loss: 1.6064\n",
      "Testing completed in 1.07m.\n",
      "Epoch 1 completed in 14.48m. 0.11m per recording.\n",
      "New highest average test accuracy: 0.0111, lowest final layer total loss: 1.6209 at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 135/135 [13:10<00:00,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 4.9418, Mel Loss: 3.3460\n",
      "Clip Loss: 5.1224, MSE Loss: 0.6815, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0089, Top 5 Accuracy: 0.0444, Top 10 Accuracy: 0.0889\n",
      "Final Layer Clip Loss: 5.4021, Final Layer MSE Loss: 0.9984, Final Layer Cosine Similarity Loss: 0.2900, Final Layer Total Loss: 1.5958\n",
      "Test unseen_subject completed., Loss: 6.4082, Mel Loss: 4.8373\n",
      "Clip Loss: 7.7665, MSE Loss: 0.4434, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0098, Top 5 Accuracy: 0.0468, Top 10 Accuracy: 0.0990\n",
      "Final Layer Clip Loss: 5.4808, Final Layer MSE Loss: 0.9203, Final Layer Cosine Similarity Loss: 0.2665, Final Layer Total Loss: 1.5709\n",
      "Test unseen_task completed., Loss: 7.1231, Mel Loss: 5.5397\n",
      "Clip Loss: 8.9317, MSE Loss: 0.4517, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0091, Top 5 Accuracy: 0.0413, Top 10 Accuracy: 0.0839\n",
      "Final Layer Clip Loss: 5.4945, Final Layer MSE Loss: 0.9409, Final Layer Cosine Similarity Loss: 0.2705, Final Layer Total Loss: 1.5835\n",
      "Test unseen_both completed., Loss: 6.3305, Mel Loss: 4.7519\n",
      "Clip Loss: 7.6273, MSE Loss: 0.4390, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0135, Top 5 Accuracy: 0.0493, Top 10 Accuracy: 0.1059\n",
      "Final Layer Clip Loss: 5.5185, Final Layer MSE Loss: 0.9206, Final Layer Cosine Similarity Loss: 0.2665, Final Layer Total Loss: 1.5785\n",
      "Testing completed in 1.03m.\n",
      "Epoch 2 completed in 14.20m. 0.11m per recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 135/135 [13:10<00:00,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 5.6301, Mel Loss: 4.1643\n",
      "Clip Loss: 6.6187, MSE Loss: 0.4828, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0089, Top 5 Accuracy: 0.0438, Top 10 Accuracy: 0.0869\n",
      "Final Layer Clip Loss: 5.1338, Final Layer MSE Loss: 0.8561, Final Layer Cosine Similarity Loss: 0.2414, Final Layer Total Loss: 1.4658\n",
      "Test unseen_subject completed., Loss: 5.1888, Mel Loss: 3.7871\n",
      "Clip Loss: 6.0766, MSE Loss: 0.3528, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0103, Top 5 Accuracy: 0.0497, Top 10 Accuracy: 0.0990\n",
      "Final Layer Clip Loss: 4.9770, Final Layer MSE Loss: 0.7932, Final Layer Cosine Similarity Loss: 0.2225, Final Layer Total Loss: 1.4017\n",
      "Test unseen_task completed., Loss: 5.6153, Mel Loss: 4.1793\n",
      "Clip Loss: 6.7207, MSE Loss: 0.3673, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0086, Top 5 Accuracy: 0.0429, Top 10 Accuracy: 0.0863\n",
      "Final Layer Clip Loss: 5.1019, Final Layer MSE Loss: 0.8125, Final Layer Cosine Similarity Loss: 0.2263, Final Layer Total Loss: 1.4359\n",
      "Test unseen_both completed., Loss: 5.1943, Mel Loss: 3.7953\n",
      "Clip Loss: 6.0900, MSE Loss: 0.3531, Commitment Loss: 0.0000\n",
      "Perplexity: 0.0000, Accuracy: 0.0086, Top 5 Accuracy: 0.0517, Top 10 Accuracy: 0.0985\n",
      "Final Layer Clip Loss: 4.9640, Final Layer MSE Loss: 0.7932, Final Layer Cosine Similarity Loss: 0.2224, Final Layer Total Loss: 1.3990\n",
      "Testing completed in 1.04m.\n",
      "Epoch 3 completed in 14.22m. 0.11m per recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  15%|█▍        | 20/135 [02:30<14:26,  7.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# del session.logger\n",
    "# del session\n",
    "\n",
    "import multiprocessing\n",
    "from train.training_session_v1 import TrainingSessionV1\n",
    "from config import TrainingConfigV1\n",
    "from config import SimpleConvConfig\n",
    "\n",
    "data_partition = {\n",
    "    \"gwilliams2023\": {\n",
    "        \"testing_subjects\": [19, 20, 21],\n",
    "        \"testing_tasks\": [0],\n",
    "    },\n",
    "    # \"armeini2022\": {\n",
    "    #     \"testing_subjects\": [],\n",
    "    #     \"testing_tasks\": [8, 9],\n",
    "    # },\n",
    "}\n",
    "\n",
    "model_config = SimpleConvConfig(\n",
    "    # Str to list of possible conditions\n",
    "    mel_normalization=False,\n",
    "    conditions={\n",
    "        \"study\": [],\n",
    "        \"subject\": [],\n",
    "    },\n",
    "    # Channels\n",
    "    in_channels=208,\n",
    "    out_channels=80,\n",
    "    hidden_dim=384,\n",
    "    dropout=0.2,\n",
    "    initial_batch_norm=True,\n",
    "    # Sensor layout settings\n",
    "    layout_dim=2,\n",
    "    layout_proj=True,\n",
    "    layout_scaling=\"minmax\",\n",
    "    # Merger with spatial attn\n",
    "    merger=False,\n",
    "    merger_emb_type=None,\n",
    "    merger_emb_dim=0,\n",
    "    merger_channels=0,\n",
    "    merger_dropout=0.0,  # Float\n",
    "    merger_conditional=None,\n",
    "    # Inital\n",
    "    initial_linear=384,\n",
    "    initial_depth=1,\n",
    "    # Conditional layers\n",
    "    conditional_layers=False,\n",
    "    conditional_layers_dim=None,  # input or hidden_dim\n",
    "    # Conv layer overall structure\n",
    "    depth=6,\n",
    "    kernel_size=3,\n",
    "    growth=1.0,\n",
    "    dilation_growth=2,\n",
    "    dilation_period=5,\n",
    "    glu=1,\n",
    "    conv_dropout=0.2,\n",
    "    dropout_input=0.2,\n",
    "    batch_norm=True,\n",
    "    half=True,\n",
    "    cnn_pos_encoding=False,\n",
    "    # Quantizer\n",
    "    quantizer=False,\n",
    "    num_codebooks=0,\n",
    "    codebook_size=0,\n",
    "    quantizer_commitment=0,\n",
    "    quantizer_temp_init=0,\n",
    "    quantizer_temp_min=0,\n",
    "    quantizer_temp_decay=0,\n",
    "    # Transformers Encoders\n",
    "    transformer_input=None,\n",
    "    transformer_encoder_emb=None,\n",
    "    transformer_encoder_layers=0,\n",
    "    transformer_encoder_heads=0,\n",
    "    # Conformer encoder variant\n",
    "    rnn_type=\"conformer\",\n",
    "    depthwise_conv_kernel_size=31,\n",
    "    use_group_norm=True,\n",
    "    convolution_first=False,\n",
    "    # Transformer Decoders\n",
    "    transformer_decoder_emb=None,\n",
    "    transformer_decoder_layers=0,\n",
    "    transformer_decoder_heads=0,\n",
    "    transformer_decoder_dim=0,\n",
    ")\n",
    "\n",
    "config = TrainingConfigV1(\n",
    "    brain_encoder_config=model_config,\n",
    "    data_partition=data_partition,\n",
    "    # Ada lora settings\n",
    "    # Around 100k total batches an epoch for gwilliams\n",
    "    adalora_init_r=12,\n",
    "    adalora_target_r=4,\n",
    "    adalora_tinit=2400,  # 5% total steps\n",
    "    adalora_tfinal=25600,  # 50-80% total steps\n",
    "    adalora_deltaT=1600,  # 1-5% total steps\n",
    "    adalora_lora_alpha=32,\n",
    "    adalora_lora_dropout=0.1,\n",
    "    adalora_total_step=32000,\n",
    "    # Pre-processing parameters\n",
    "    # Brain\n",
    "    new_freq=200,\n",
    "    frequency_bands={\"all\": (0.5, 80)},\n",
    "    max_random_shift=1.0,\n",
    "    window_size=4,\n",
    "    window_stride=1,\n",
    "    brain_clipping=None,\n",
    "    baseline_window=0.5,\n",
    "    notch_filter=True,\n",
    "    scaling=\"both\",\n",
    "    delay=0.15,\n",
    "    # Hyperparameters\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=1e-4,\n",
    "    epochs=40,\n",
    "    batch_size=128,\n",
    "    random_test_size=10,\n",
    "    seed=42,\n",
    "    mel_alignment_objectives={\n",
    "        \"clip_loss\": 0.6,\n",
    "        \"mse_loss\": 0.4,\n",
    "        \"commitment_loss\": 0.0,\n",
    "    },\n",
    "    latent_alignment_objectives={\n",
    "        \"cosine_similarity\": 0.4,\n",
    "        \"mse_loss\": 0.4,\n",
    "        \"clip_loss\": 0.2,\n",
    "    },\n",
    "    latent_alignment_layers=[-1],\n",
    ")\n",
    "\n",
    "config.learning_rate = 3e-3\n",
    "config.brain_encoder_config.mel_normalization = True\n",
    "\n",
    "\n",
    "session = TrainingSessionV1(\n",
    "    config=config,\n",
    "    studies={study: \"audio\" for study in data_partition.keys()},\n",
    "    data_path=\"/home/ubuntu/storage/data\",\n",
    "    save_path=\"saves/phase2/objectives/CLIP_MSE_TEST2\",\n",
    "    clear_cache=False,\n",
    "    cache_name=\"cache\",\n",
    ")\n",
    "\n",
    "try:\n",
    "    session.train(\n",
    "        device=\"cuda\",\n",
    "        buffer_size=30,\n",
    "        num_workers=(multiprocessing.cpu_count() - 2),\n",
    "        max_cache_size=400,\n",
    "        current_epoch=0,\n",
    "    )\n",
    "except KeyboardInterrupt as e:\n",
    "    print(\"Exited\")\n",
    "\n",
    "# try:\n",
    "#     session.pre_process_all_recordings(\n",
    "#         buffer_size=30, num_workers=multiprocessing.cpu_count() - 2, max_cache_size=400\n",
    "#     )\n",
    "# except KeyboardInterrupt as e:\n",
    "#     print(\"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# torch.cuda.get_device_capability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in session.model.encoder.named_parameters():\n",
    "#     if \"lora_A\" in name or \"lora_B\" in name or \"lora_E\" in name:\n",
    "#         print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 22:05:48,032\tINFO worker.py:1841 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total recordings: 135\n",
      "Processed 10 recordings of 135\n",
      "Processed 20 recordings of 135\n",
      "Processed 30 recordings of 135\n",
      "Processed 40 recordings of 135\n",
      "Processed 50 recordings of 135\n",
      "Processed 60 recordings of 135\n",
      "Processed 70 recordings of 135\n",
      "Processed 80 recordings of 135\n",
      "Processed 90 recordings of 135\n",
      "Processed 100 recordings of 135\n",
      "Processed 110 recordings of 135\n",
      "Processed 120 recordings of 135\n",
      "Processed 130 recordings of 135\n",
      "Batch 100895 (135 recordings) processed in 140.85s\n",
      "Average processing time per recording: 1.04s\n",
      "Average processing time per batch: 0.00s\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "\n",
    "# dataloader = session.get_dataloader(buffer_size=30, num_workers=24, max_cache_size=400)\n",
    "# dataloader.start_fetching(session.dataset[\"train\"], cache=True)\n",
    "\n",
    "# # Process batches as they become available\n",
    "# try:\n",
    "#     batches, recs, start_time = 0, 0, time.time()\n",
    "#     print(f\"Total recordings: {len(session.dataset['train'])}\")\n",
    "\n",
    "#     while True:\n",
    "#         batch = dataloader.get_recording()\n",
    "\n",
    "#         if batch is None:\n",
    "#             break\n",
    "\n",
    "#         brain = batch.brain_segments[\"all\"]\n",
    "#         batches += brain.shape[0]\n",
    "#         recs += 1\n",
    "\n",
    "#         if recs % 10 == 0:\n",
    "#             print(f'Processed {recs} recordings of {len(session.dataset[\"train\"])}')\n",
    "\n",
    "#     print(\n",
    "#         f\"Batch {batches} ({recs} recordings) processed in {time.time() - start_time:.2f}s\"\n",
    "#     )\n",
    "#     print(\n",
    "#         f\"Average processing time per recording: {(time.time() - start_time) / recs:.2f}s\"\n",
    "#     )\n",
    "#     print(\n",
    "#         f\"Average processing time per batch: {(time.time() - start_time) / batches:.2f}s\"\n",
    "#     )\n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"Interrupted\")\n",
    "#     dataloader.stop()\n",
    "# except Exception as e:\n",
    "#     print(\"Error\", e)\n",
    "#     dataloader.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
