{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gwilliams2023 with batch type audiotext\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "onset",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "duration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "word",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7ce02250-e3a5-4598-a051-a0a0c95c6648",
       "rows": [
        [
         "0",
         "23.506",
         "0.3",
         "Tara"
        ],
        [
         "1",
         "23.816",
         "0.24",
         "stood"
        ],
        [
         "2",
         "24.056",
         "0.37",
         "stock"
        ],
        [
         "3",
         "24.586",
         "0.3999999999999999",
         "still"
        ],
        [
         "4",
         "25.136",
         "0.4100000000000001",
         "waiting"
        ],
        [
         "5",
         "25.546",
         "0.1299999999999999",
         "for"
        ],
        [
         "6",
         "25.676",
         "0.0899999999999998",
         "the"
        ],
        [
         "7",
         "25.766",
         "0.27",
         "first"
        ],
        [
         "8",
         "26.046",
         "0.31",
         "tiny"
        ],
        [
         "9",
         "26.356",
         "0.2399999999999997",
         "gleam"
        ],
        [
         "10",
         "26.606",
         "0.1799999999999997",
         "from"
        ],
        [
         "11",
         "26.786",
         "0.0700000000000002",
         "the"
        ],
        [
         "12",
         "26.856",
         "0.29",
         "scout"
        ],
        [
         "13",
         "27.146",
         "0.29",
         "craft"
        ],
        [
         "14",
         "27.446",
         "0.1499999999999999",
         "to"
        ],
        [
         "15",
         "27.596",
         "0.2800000000000002",
         "appear"
        ],
        [
         "16",
         "27.876",
         "0.08",
         "in"
        ],
        [
         "17",
         "27.956",
         "0.0899999999999998",
         "the"
        ],
        [
         "18",
         "28.046",
         "0.4199999999999999",
         "darkness"
        ],
        [
         "19",
         "28.466",
         "0.1399999999999996",
         "of"
        ],
        [
         "20",
         "28.606",
         "0.0900000000000007",
         "the"
        ],
        [
         "21",
         "29.756",
         "0.1399999999999996",
         "The"
        ],
        [
         "22",
         "29.896",
         "0.3900000000000005",
         "gentle"
        ],
        [
         "23",
         "30.286",
         "0.4199999999999999",
         "constant"
        ],
        [
         "24",
         "30.706",
         "0.2099999999999999",
         "breeze"
        ],
        [
         "25",
         "30.916",
         "0.1200000000000001",
         "of"
        ],
        [
         "26",
         "31.036",
         "0.4100000000000001",
         "recycled"
        ],
        [
         "27",
         "31.476",
         "0.160000000000001",
         "air"
        ],
        [
         "28",
         "31.636",
         "0.1599999999999983",
         "from"
        ],
        [
         "29",
         "31.796",
         "0.0900000000000016",
         "the"
        ],
        [
         "30",
         "31.886",
         "0.2399999999999984",
         "vent"
        ],
        [
         "31",
         "32.126",
         "0.200000000000001",
         "above"
        ],
        [
         "32",
         "32.336",
         "0.1999999999999993",
         "blew"
        ],
        [
         "33",
         "32.536",
         "0.1100000000000012",
         "an"
        ],
        [
         "34",
         "32.646",
         "0.3900000000000005",
         "annoying"
        ],
        [
         "35",
         "33.036",
         "0.1699999999999999",
         "hair"
        ],
        [
         "36",
         "33.206",
         "0.3500000000000014",
         "against"
        ],
        [
         "37",
         "33.556",
         "0.1399999999999988",
         "her"
        ],
        [
         "38",
         "33.696",
         "0.3900000000000005",
         "nose"
        ],
        [
         "39",
         "34.246",
         "0.1999999999999993",
         "but"
        ],
        [
         "40",
         "34.446",
         "0.1699999999999999",
         "she"
        ],
        [
         "41",
         "34.616",
         "0.3000000000000007",
         "ignored"
        ],
        [
         "42",
         "34.916",
         "0.1600000000000001",
         "it"
        ],
        [
         "43",
         "35.396",
         "0.1100000000000012",
         "A"
        ],
        [
         "44",
         "35.506",
         "0.4700000000000006",
         "gasp"
        ],
        [
         "45",
         "35.986",
         "0.2699999999999996",
         "from"
        ],
        [
         "46",
         "36.256",
         "0.1300000000000007",
         "the"
        ],
        [
         "47",
         "36.386",
         "0.5399999999999991",
         "psychic"
        ],
        [
         "48",
         "36.926",
         "0.3200000000000003",
         "broke"
        ],
        [
         "49",
         "37.256",
         "0.1999999999999993",
         "her"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 668
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.506</td>\n",
       "      <td>0.30</td>\n",
       "      <td>Tara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.816</td>\n",
       "      <td>0.24</td>\n",
       "      <td>stood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.056</td>\n",
       "      <td>0.37</td>\n",
       "      <td>stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.586</td>\n",
       "      <td>0.40</td>\n",
       "      <td>still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.136</td>\n",
       "      <td>0.41</td>\n",
       "      <td>waiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>361.097</td>\n",
       "      <td>0.17</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>361.277</td>\n",
       "      <td>0.14</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>361.487</td>\n",
       "      <td>0.58</td>\n",
       "      <td>project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>362.207</td>\n",
       "      <td>0.15</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>362.817</td>\n",
       "      <td>0.34</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       onset  duration     word\n",
       "0     23.506      0.30     Tara\n",
       "1     23.816      0.24    stood\n",
       "2     24.056      0.37    stock\n",
       "3     24.586      0.40    still\n",
       "4     25.136      0.41  waiting\n",
       "..       ...       ...      ...\n",
       "663  361.097      0.17      end\n",
       "664  361.277      0.14      for\n",
       "665  361.487      0.58  project\n",
       "666  362.207      0.15      and\n",
       "667  362.817      0.34  species\n",
       "\n",
       "[668 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from studies.gwilliams2023 import Gwilliams2023\n",
    "from studies.armeini2022 import Armeini2022\n",
    "\n",
    "\n",
    "study = Gwilliams2023(\n",
    "    batch_type=\"audiotext\",\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "rec = study.recordings[0][0][0]\n",
    "raw = rec.load_raw(load_data=True)\n",
    "events = rec.load_events(raw, options=\"both\")\n",
    "word_events = events[\"word\"]\n",
    "word_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 21:09:11,820\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[50257, 50362, 50363,  ..., 50256, 50256, 50256],\n",
       "        [50257, 50362, 50367,  ..., 50256, 50256, 50256],\n",
       "        [50257, 50362, 50370,  ..., 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [50257, 50362, 50412,  ..., 50256, 50256, 50256],\n",
       "        [50257, 50362, 50370,  ..., 50256, 50256, 50256],\n",
       "        [50257, 50362, 50376,  ..., 50256, 50256, 50256]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tkinter import TRUE\n",
    "from dataloader import DataLoader\n",
    "\n",
    "add_timestamps = True\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    buffer_size=30,\n",
    "    max_cache_size_gb=400,\n",
    "    cache_dir=\"cache\",\n",
    "    notch_filter=True,\n",
    "    frequency_bands={\"all\": (0.5, 80)},\n",
    "    scaling=\"both\",\n",
    "    brain_clipping=None,\n",
    "    baseline_window=0.5,\n",
    "    new_freq=200,\n",
    "    delay=0.15,\n",
    "    batch_types={\"audiotext\": 1},\n",
    "    batch_kwargs={\n",
    "        \"audiotext\": {\n",
    "            \"max_random_shift\": 1.0,\n",
    "            \"window_size\": 4,\n",
    "            \"window_stride\": 1,\n",
    "            \"audio_sample_rate\": 16000,\n",
    "            \"hop_length\": 160,\n",
    "            \"audio_processor\": \"openai/whisper-tiny.en\",\n",
    "            \"add_timestamps\": add_timestamps,\n",
    "            \"tokenize\": TRUE,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "dataloader.start_fetching(recordings=[rec])\n",
    "batch = dataloader.get_recording()\n",
    "\n",
    "brain, audio, transcript, transcript_attention_masks, recording = (\n",
    "    batch.brain_segments[\"all\"],  # .to(device)\n",
    "    batch.audio_segments,  # .to(device)\n",
    "    batch.transcript,\n",
    "    batch.transcript_attention_masks,\n",
    "    batch.recording,\n",
    ")\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "\n",
    "# def remove_timestamps(transcript_line: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Removes <|x.xx|> and with space patterns from a single transcript line.\n",
    "#     \"\"\"\n",
    "#     pattern = r\"<\\|\\d+(\\.\\d+)?\\|>\\s?\"\n",
    "#     return re.sub(pattern, \"\", transcript_line).strip()\n",
    "\n",
    "\n",
    "# def clean_timestamped_transcript(transcript_lines):\n",
    "#     \"\"\"\n",
    "#     Removes timestamp tokens from a list of transcript lines.\n",
    "#     Returns a list of cleaned lines.\n",
    "#     \"\"\"\n",
    "#     return [remove_timestamps(line) for line in transcript_lines]\n",
    "\n",
    "\n",
    "# transcript_no_timestamps = clean_timestamped_transcript(transcript)\n",
    "# transcript_no_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tara stood stock still waiting for the first tiny gleam from the scout craft',\n",
       " 'waiting for the first tiny gleam from the scout craft to appear in the darkness of the',\n",
       " 'from the scout craft to appear in the darkness of the The gentle',\n",
       " 'the darkness of the The gentle constant breeze of recycled air from the',\n",
       " 'The gentle constant breeze of recycled air from the vent above blew an annoying hair',\n",
       " 'air from the vent above blew an annoying hair against her nose but she ignored it',\n",
       " 'hair against her nose but she ignored it A gasp from the',\n",
       " 'ignored it A gasp from the psychic broke her silent',\n",
       " 'from the psychic broke her silent vigil and she',\n",
       " 'vigil and she turned Results',\n",
       " 'and she turned Results Harmon she',\n",
       " 'Harmon she suppressed the surge of annoyance that',\n",
       " 'she suppressed the surge of annoyance that ran through her as she',\n",
       " 'the surge of annoyance that ran through her as she contemplated the',\n",
       " 'through her as she contemplated the gift of getting all the',\n",
       " 'the gift of getting all the hot news first',\n",
       " 'all the hot news first face',\n",
       " 'face slowly animated',\n",
       " 'face slowly animated joy sweeping in',\n",
       " 'animated joy sweeping in to replace stern',\n",
       " 'sweeping in to replace stern concentration',\n",
       " 'replace stern concentration says the',\n",
       " 'says the',\n",
       " 'says the',\n",
       " '',\n",
       " 'planet tiny away',\n",
       " 'planet tiny away contemplated to not blonde',\n",
       " 'contemplated to not blonde slowly broke by',\n",
       " 'blonde slowly broke by',\n",
       " 'Thriving with life',\n",
       " 'with life large and small forms',\n",
       " 'large and small forms no buildings of any',\n",
       " 'no buildings of any kind',\n",
       " 'any kind metals and',\n",
       " 'metals and stable',\n",
       " 'metals and stable atmosphere excellent onto the',\n",
       " 'stable atmosphere excellent onto the',\n",
       " 'excellent onto the only head',\n",
       " 'only head planet pointed blackness now get',\n",
       " 'head planet pointed blackness now get gentle imposing',\n",
       " 'now get gentle imposing alpha',\n",
       " 'imposing alpha',\n",
       " '',\n",
       " '',\n",
       " 'He says we',\n",
       " 'He says we should come now',\n",
       " 'come now immediately before the probe is',\n",
       " 'before the probe is reported late',\n",
       " 'the probe is reported late Harmon that',\n",
       " 'late Harmon that good nothing son',\n",
       " 'Harmon that good nothing son of beta get his',\n",
       " 'good nothing son of beta get his the gate and',\n",
       " 'get his the gate and here NOW',\n",
       " 'gate and here NOW or open fire on him',\n",
       " 'or open fire on him when we come',\n",
       " 'on him when we come Tara Of',\n",
       " 'Tara Of all the',\n",
       " 'Of all the',\n",
       " 'the no',\n",
       " 'no doubt with orders from',\n",
       " 'no doubt with orders from Mason was questioning her',\n",
       " 'what I get for not using mercenaries',\n",
       " 'She returned to her watch',\n",
       " 'She returned to her watch regarding her own',\n",
       " 'to her watch regarding her own reflection in the long',\n",
       " 'her own reflection in the long window',\n",
       " 'in the long window Mahogany black',\n",
       " 'Mahogany black curly hair cut',\n",
       " 'black curly hair cut short in the typical',\n",
       " 'hair cut short in the typical military style framed a',\n",
       " 'in the typical military style framed a',\n",
       " 'a dark skinned face',\n",
       " 'dark skinned face It was not an',\n",
       " 'skinned face It was not an attractive face',\n",
       " 'It was not an attractive face right now her ebony eyes',\n",
       " 'face right now her ebony eyes by',\n",
       " 'her ebony eyes by hours on the watch',\n",
       " 'by hours on the watch full lips with',\n",
       " 'full lips with frustration She had the',\n",
       " 'with frustration She had the look of every',\n",
       " 'She had the look of every leader she had ever known',\n",
       " 'of every leader she had ever known At six foot',\n",
       " 'ever known At six foot two she stood a',\n",
       " 'At six foot two she stood a full head taller than',\n",
       " 'she stood a full head taller than even her',\n",
       " 'a full head taller than even her first officer',\n",
       " 'her first officer than golden craft',\n",
       " 'officer than golden craft blew prepare color',\n",
       " 'craft blew prepare color attractive crew',\n",
       " 'color attractive crew Her expression',\n",
       " 'Her expression completed the imposing',\n",
       " 'expression completed the imposing effect She',\n",
       " 'completed the imposing effect She picked imaginary',\n",
       " 'She picked imaginary flecks off her stark gray',\n",
       " 'flecks off her stark gray jumpsuit and snorted',\n",
       " 'gray jumpsuit and snorted You look like',\n",
       " 'and snorted You look like hell Tar',\n",
       " 'You look like hell Tar',\n",
       " 'Tar blow this',\n",
       " 'blow this let fatigue get to',\n",
       " 'let fatigue get to you She',\n",
       " 'get to you She used the discretion of the',\n",
       " 'She used the discretion of the mirrored window',\n",
       " 'of the mirrored window',\n",
       " '',\n",
       " '',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to defy United',\n",
       " 'to defy United Earth Command and sever',\n",
       " 'to defy United Earth Command and sever all ties from',\n",
       " 'She watched the psi bob her head unaware of the rest of the',\n",
       " 'her head unaware of the rest of the bridge shaking blonde',\n",
       " 'of the bridge shaking blonde curls as she away with the',\n",
       " 'blonde curls as she away with the approaching psi',\n",
       " 'she away with the approaching psi relay on',\n",
       " 'approaching psi relay on ship She seemed',\n",
       " 'on ship She seemed so',\n",
       " 'so self conscious and shallow on the',\n",
       " 'conscious and shallow on the outside but having that',\n",
       " 'the outside but having that incredible gift',\n",
       " 'but having that incredible gift There had to be more to',\n",
       " 'gift There had to be more to her',\n",
       " 'had to be more to her Well if she pan',\n",
       " 'Well if she pan out be',\n",
       " 'if she pan out be terminated',\n",
       " 'out be terminated Any crew',\n",
       " 'Any crew member that would',\n",
       " 'crew member that would jeopardize the project was meat',\n",
       " 'jeopardize the project was meat It would be a shame to',\n",
       " 'was meat It would be a shame to lose that talent',\n",
       " 'would be a shame to lose that talent though',\n",
       " 'though her first',\n",
       " 'her first officer was staring',\n",
       " 'officer was staring at his panel',\n",
       " 'at his panel color psychic metals',\n",
       " 'panel color psychic metals system which for all',\n",
       " 'metals system which for all charges if this discretion meat',\n",
       " 'all charges if this discretion meat any insurrection air member',\n",
       " 'meat any insurrection air member',\n",
       " 'air member He was what this was all',\n",
       " 'He was what this was all about She watched his',\n",
       " 'She watched his graceful fingers ending in thick',\n",
       " 'graceful fingers ending in thick black claws tap out',\n",
       " 'ending in thick black claws tap out calculations on the',\n",
       " 'claws tap out calculations on the panel',\n",
       " 'on the panel His pointed ears',\n",
       " 'His pointed ears back and forth',\n",
       " 'ears back and forth catching every sound from the',\n",
       " 'catching every sound from the bridge while his',\n",
       " 'the bridge while his long tail swished to the rhythm of his',\n",
       " 'long tail swished to the rhythm of his thoughts',\n",
       " 'thoughts Only those of the',\n",
       " 'Only those of the Insurrection inner team knew he',\n",
       " 'the Insurrection inner team knew he was no common',\n",
       " 'team knew he was no common beta furry',\n",
       " 'no common beta furry His silken fur',\n",
       " 'His silken fur which would be',\n",
       " 'fur which would be golden and striped with',\n",
       " 'be golden and striped with jet black bands was',\n",
       " 'with jet black bands was dyed perfectly to a pure',\n",
       " 'dyed perfectly to a pure black and his mane trimmed and thinned',\n",
       " 'black and his mane trimmed and thinned as to be',\n",
       " 'trimmed and thinned as to be indistinguishable from the rest of his',\n",
       " 'indistinguishable from the rest of his coat',\n",
       " 'of his coat His eyes had been treated and darkened to a',\n",
       " 'His eyes had been treated and darkened to a rich purple to disguise the',\n",
       " 'and darkened to a rich purple to disguise the brilliant golden yellow color that would mark him as',\n",
       " 'Right now he looked like an overgrown wolf learned touch typing',\n",
       " 'wolf learned touch typing The scout ship from the',\n",
       " 'typing The scout ship from the hole a brilliant speck',\n",
       " 'ship from the hole a brilliant speck emerging from a sphere of',\n",
       " 'a brilliant speck emerging from a sphere of velvety blackness',\n",
       " 'emerging from a sphere of velvety blackness It s hail',\n",
       " 'velvety blackness It s hail across the and Tara',\n",
       " 'hail across the and Tara spun to retake her seat at the helm',\n",
       " 'and Tara spun to retake her seat at the helm Launch the',\n",
       " 'her seat at the helm Launch the second probe',\n",
       " 'Launch the second probe Central be crushed to learn that another',\n",
       " 'Central be crushed to learn that another gateway has yielded little more than a',\n",
       " 'that another gateway has yielded little more than a class F planet and a white dwarf',\n",
       " 'than a class F planet and a white dwarf system Level',\n",
       " 'dwarf system Level and',\n",
       " 'and',\n",
       " 'and',\n",
       " '',\n",
       " '',\n",
       " 'and let loose a',\n",
       " 'and let loose a small growl as if ro',\n",
       " 'let loose a small growl as if ro caution his charges against false',\n",
       " 'if ro caution his charges against false hope',\n",
       " 'false hope twenty seven gates so',\n",
       " 'twenty seven gates so far and none had turned up anything',\n",
       " 'gates so far and none had turned up anything worth time',\n",
       " 'up anything worth time military jumpsuit it waiting',\n",
       " 'military jumpsuit it waiting those six',\n",
       " 'those six reflection fatigue Tara would',\n",
       " 'six reflection fatigue Tara would not let giddy hopes drag them onto',\n",
       " 'would not let giddy hopes drag them onto a rock that would spell end for']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import WhisperTokenizerFast\n",
    "\n",
    "predict_timestamps = add_timestamps\n",
    "add_prefix_space = True\n",
    "\n",
    "tokenizer = WhisperTokenizerFast.from_pretrained(\n",
    "    \"openai/whisper-tiny.en\",\n",
    "    predict_timestamps=predict_timestamps,\n",
    "    add_prefix_space=add_prefix_space,\n",
    ")\n",
    "\n",
    "# encoded = tokenizer(\n",
    "#     transcript,\n",
    "#     return_tensors=\"pt\",\n",
    "#     padding=\"max_length\",\n",
    "#     truncation=True,\n",
    "#     max_length=64,  # 16 * int(windows)\n",
    "# )\n",
    "# input_ids, attention_mask = encoded[\"input_ids\"], encoded[\"attention_mask\"]\n",
    "\n",
    "skip_special_tokens = True\n",
    "decode_with_timestamps = False\n",
    "\n",
    "decoded = tokenizer.batch_decode(\n",
    "    sequences=transcript,\n",
    "    skip_special_tokens=skip_special_tokens,\n",
    "    decode_with_timestamps=decode_with_timestamps,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "decoded = [\" \".join(word.split()) for word in decoded]\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNEncoder initialized as conformer with 4 layers, 256 d_model, 4 nhead\n",
      "\tEmbedding: sinusoidal, params: 6075392\n",
      "SimpleConv initialized with 8927984 parameters, cond: ['study', 'subject']\n",
      "Merger False, merger channels 0\n",
      "ConvBlocks: 4, hidden_dim: 256, params 2626048\n",
      "Found 40 target modules for AdaLora: ['model.decoder.layers.0.self_attn.k_proj', 'model.decoder.layers.0.self_attn.v_proj', 'model.decoder.layers.0.self_attn.q_proj', 'model.decoder.layers.0.self_attn.out_proj', 'model.decoder.layers.0.encoder_attn.k_proj', 'model.decoder.layers.0.encoder_attn.v_proj', 'model.decoder.layers.0.encoder_attn.q_proj', 'model.decoder.layers.0.encoder_attn.out_proj', 'model.decoder.layers.0.fc1', 'model.decoder.layers.0.fc2', 'model.decoder.layers.1.self_attn.k_proj', 'model.decoder.layers.1.self_attn.v_proj', 'model.decoder.layers.1.self_attn.q_proj', 'model.decoder.layers.1.self_attn.out_proj', 'model.decoder.layers.1.encoder_attn.k_proj', 'model.decoder.layers.1.encoder_attn.v_proj', 'model.decoder.layers.1.encoder_attn.q_proj', 'model.decoder.layers.1.encoder_attn.out_proj', 'model.decoder.layers.1.fc1', 'model.decoder.layers.1.fc2', 'model.decoder.layers.2.self_attn.k_proj', 'model.decoder.layers.2.self_attn.v_proj', 'model.decoder.layers.2.self_attn.q_proj', 'model.decoder.layers.2.self_attn.out_proj', 'model.decoder.layers.2.encoder_attn.k_proj', 'model.decoder.layers.2.encoder_attn.v_proj', 'model.decoder.layers.2.encoder_attn.q_proj', 'model.decoder.layers.2.encoder_attn.out_proj', 'model.decoder.layers.2.fc1', 'model.decoder.layers.2.fc2', 'model.decoder.layers.3.self_attn.k_proj', 'model.decoder.layers.3.self_attn.v_proj', 'model.decoder.layers.3.self_attn.q_proj', 'model.decoder.layers.3.self_attn.out_proj', 'model.decoder.layers.3.encoder_attn.k_proj', 'model.decoder.layers.3.encoder_attn.v_proj', 'model.decoder.layers.3.encoder_attn.q_proj', 'model.decoder.layers.3.encoder_attn.out_proj', 'model.decoder.layers.3.fc1', 'model.decoder.layers.3.fc2']\n",
      "openai/whisper-tiny.en loaded with total params = 38240008.\n",
      "AdaLora has 479712 trainable params after target module setup.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from config import SimpleConvConfig\n",
    "from peft import AdaLoraConfig\n",
    "from models.whisper_decoder import WhisperDecoder\n",
    "\n",
    "\n",
    "brain_module_config = SimpleConvConfig(\n",
    "    # Str to list of possible conditions\n",
    "    mel_normalization=False,\n",
    "    conditions={\n",
    "        \"study\": [],\n",
    "        \"subject\": [],\n",
    "    },\n",
    "    # Channels\n",
    "    in_channels=208,\n",
    "    out_channels=80,\n",
    "    hidden_dim=256,\n",
    "    dropout=0.2,\n",
    "    initial_batch_norm=True,\n",
    "    # Sensor layout settings\n",
    "    layout_dim=2,\n",
    "    layout_proj=True,\n",
    "    layout_scaling=\"minmax\",\n",
    "    # Merger with spatial attn\n",
    "    merger=False,\n",
    "    merger_emb_type=None,\n",
    "    merger_emb_dim=0,\n",
    "    merger_channels=0,\n",
    "    merger_dropout=0.0,  # Float\n",
    "    merger_conditional=None,\n",
    "    # Inital\n",
    "    initial_linear=256,\n",
    "    initial_depth=1,\n",
    "    # Conditional layers\n",
    "    conditional_layers=False,\n",
    "    conditional_layers_dim=None,  # input or hidden_dim\n",
    "    # Conv layer overall structure\n",
    "    depth=4,\n",
    "    kernel_size=3,\n",
    "    growth=1.0,\n",
    "    dilation_growth=2,\n",
    "    dilation_period=5,\n",
    "    glu=1,\n",
    "    conv_dropout=0.2,\n",
    "    dropout_input=0.1,\n",
    "    batch_norm=True,\n",
    "    half=True,\n",
    "    cnn_pos_encoding=False,\n",
    "    # Quantizer\n",
    "    quantizer=False,\n",
    "    num_codebooks=0,\n",
    "    codebook_size=0,\n",
    "    quantizer_commitment=0,\n",
    "    quantizer_temp_init=0,\n",
    "    quantizer_temp_min=0,\n",
    "    quantizer_temp_decay=0,\n",
    "    # Transformers Encoders\n",
    "    transformer_input=\"continuous\",\n",
    "    transformer_encoder_emb=\"sinusoidal\",\n",
    "    transformer_encoder_layers=4,\n",
    "    transformer_encoder_heads=4,\n",
    "    # Conformer encoder variant\n",
    "    rnn_type=\"conformer\",\n",
    "    depthwise_conv_kernel_size=15,\n",
    "    use_group_norm=False,\n",
    "    convolution_first=False,\n",
    "    # Transformer Decoders\n",
    "    transformer_decoder_emb=None,\n",
    "    transformer_decoder_layers=0,\n",
    "    transformer_decoder_heads=0,\n",
    "    transformer_decoder_dim=0,\n",
    ")\n",
    "\n",
    "adalora_init_r = 12\n",
    "adalora_target_r = 4\n",
    "adalora_tinit = 450 * 3  # 5% total steps\n",
    "adalora_tfinal = 450 * 8  # 50-80% total steps\n",
    "adalora_deltaT = 450 * 1  # 1-5% total steps\n",
    "adalora_lora_alpha = 32\n",
    "adalora_lora_dropout = 0.1\n",
    "adalora_total_step = 450 * 50\n",
    "\n",
    "adalora_config = AdaLoraConfig(\n",
    "    peft_type=\"ADALORA\",\n",
    "    task_type=\"SPEECH_RECOGNITION\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\", \"fc1\", \"fc2\"],\n",
    "    init_r=adalora_init_r,\n",
    "    target_r=adalora_target_r,\n",
    "    tinit=adalora_tinit,\n",
    "    tfinal=adalora_tfinal,\n",
    "    deltaT=adalora_deltaT,\n",
    "    lora_alpha=adalora_lora_alpha,\n",
    "    lora_dropout=adalora_lora_dropout,\n",
    "    total_step=adalora_total_step,\n",
    ")\n",
    "\n",
    "model = WhisperDecoder(\n",
    "    brain_module_config=brain_module_config,\n",
    "    adalora_config=adalora_config,\n",
    "    device=\"mps\",\n",
    "    audio_model_id=\"openai/whisper-tiny.en\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Terror stood stock, still, waiting for the first tiny gleam from the scout craft',\n",
       " ' Waiting for the first tiny gleam from the scout craft to appear in the darkness of the wormhole',\n",
       " ' The scene from the scout craft to appear in the darkness of the wormhole. The gentle concept',\n",
       " ' In the darkness of the wormhole, the gentle constant rays of recycled air from the',\n",
       " ' The gentle constant rays of recycled air from the vent above blue and annoying hair again.',\n",
       " ' air from the vent above Lewin annoying hair against her nose, but she ignored it.',\n",
       " ' Annoying her against her nose, but she ignored it. A gasp from the side',\n",
       " ' She ignored it. A gasp from the psychic broke her silent vigil.',\n",
       " ' She asked from the psychic broke her silent vigil, and she turned',\n",
       " ' silent vigil, and she turned, results, harm',\n",
       " ' And she turned. Results, harm and rah she suppressed.',\n",
       " ' As a result, harm in Rashi suppressed the surge of annoyance that Rashi',\n",
       " ' In Rauh she suppressed the surge of annoyance that ran through her as she called her.',\n",
       " ' The search of annoyance that Ryan threw her as she contemplated the sound of the man.',\n",
       " ' And through her, she contemplated the size gift of getting all the heart',\n",
       " ' plated the size gift of getting all the hot news first.',\n",
       " ' all the hot news first. Harments face slowly.',\n",
       " ' first. Harments face slowly animated.',\n",
       " \" Harmon's face slowly animated, joy sweeping and swa-\",\n",
       " ' The animated, joy-swoeping and swarded to replace stern cons']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 20\n",
    "\n",
    "brain_input = brain[:idx].to(\"mps\")\n",
    "attention_mask_input = transcript_attention_masks[:idx].to(\"mps\")\n",
    "input_ids_input = transcript[:idx].to(\"mps\")\n",
    "audio_input = audio[:idx].to(\"mps\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     output = model(\n",
    "#         x=[brain_input],\n",
    "#         recording=[recording],\n",
    "#         conditions=[{}],\n",
    "#         mel=None,\n",
    "#         train=False,\n",
    "#         return_hidden_outputs=False,\n",
    "#         attention_mask=None,\n",
    "#         labels=input_ids_input,\n",
    "#         decoder_attention_mask=attention_mask_input,\n",
    "#     )\n",
    "\n",
    "# (\n",
    "#     x,  # predicted mel\n",
    "#     quantizer_metrics,\n",
    "#     channel_weights,\n",
    "#     hidden_outputs,\n",
    "#     encoder_last_hidden_state,\n",
    "#     ce_loss,\n",
    "# ) = output\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    (\n",
    "        output_token_ids,  # [B, T]\n",
    "        x,  # [B, 80, T']\n",
    "        quantizer_metrics,\n",
    "        channel_weights,\n",
    "        hidden_outputs,\n",
    "    ) = model.generate(\n",
    "        x=None,  # [brain_input],\n",
    "        recording=[recording],\n",
    "        conditions=[{}],\n",
    "        mel=audio_input,\n",
    "        max_new_tokens=128,\n",
    "        attention_mask=None,\n",
    "        return_hidden_outputs=False,\n",
    "    )\n",
    "output_token_ids_decoded = tokenizer.batch_decode(\n",
    "    sequences=output_token_ids,\n",
    "    skip_special_tokens=True,\n",
    "    decode_with_timestamps=False,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "output_token_ids_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50257, 50362, 50363,  ..., 50256, 50256, 50256],\n",
       "        [50257, 50362, 50367,  ..., 50256, 50256, 50256],\n",
       "        [50257, 50362, 50370,  ..., 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [50257, 50362, 50412,  ..., 50256, 50256, 50256],\n",
       "        [50257, 50362, 50370,  ..., 50256, 50256, 50256],\n",
       "        [50257, 50362, 50376,  ..., 50256, 50256, 50256]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tara stood stock still waiting for the first tiny gleam from the scout craft',\n",
       " 'waiting for the first tiny gleam from the scout craft to appear in the darkness of the',\n",
       " 'from the scout craft to appear in the darkness of the The gentle',\n",
       " 'the darkness of the The gentle constant breeze of recycled air from the',\n",
       " 'The gentle constant breeze of recycled air from the vent above blew an annoying hair',\n",
       " 'air from the vent above blew an annoying hair against her nose but she ignored it',\n",
       " 'hair against her nose but she ignored it A gasp from the',\n",
       " 'ignored it A gasp from the psychic broke her silent',\n",
       " 'from the psychic broke her silent vigil and she',\n",
       " 'vigil and she turned Results',\n",
       " 'and she turned Results Harmon she',\n",
       " 'Harmon she suppressed the surge of annoyance that',\n",
       " 'she suppressed the surge of annoyance that ran through her as she',\n",
       " 'the surge of annoyance that ran through her as she contemplated the',\n",
       " 'through her as she contemplated the gift of getting all the',\n",
       " 'the gift of getting all the hot news first',\n",
       " 'all the hot news first face',\n",
       " 'face slowly animated',\n",
       " 'face slowly animated joy sweeping in',\n",
       " 'animated joy sweeping in to replace stern']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_input_decoded = tokenizer.batch_decode(\n",
    "    sequences=input_ids_input,\n",
    "    skip_special_tokens=True,\n",
    "    decode_with_timestamps=False,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "input_ids_input_decoded = [\" \".join(word.split()) for word in input_ids_input_decoded]\n",
    "input_ids_input_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.5525711421877697,\n",
       " 'rouge_f': 0.801990348361316,\n",
       " 'bert_score': 0.7344756722450256,\n",
       " 'cer': 0.3867017566453689,\n",
       " 'self_bleu': 0.034513324789303225}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.nlp_metrics import nlp_metrics\n",
    "\n",
    "metrics = nlp_metrics(output_token_ids_decoded, input_ids_input_decoded)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
