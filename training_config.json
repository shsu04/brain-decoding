{
    "data_partition": {
        "gwilliams2023": {
            "testing_subjects": [
                19,
                20,
                21
            ],
            "testing_tasks": [
                0
            ]
        }
    },
    "adalora_init_r": 12,
    "adalora_target_r": 4,
    "adalora_tinit": 1350,
    "adalora_tfinal": 3600,
    "adalora_deltaT": 450,
    "adalora_lora_alpha": 32,
    "adalora_lora_dropout": 0.1,
    "adalora_total_step": 22500,
    "new_freq": 200,
    "frequency_bands": {
        "all": [
            0.5,
            80
        ]
    },
    "max_random_shift": 1.0,
    "window_size": 4,
    "window_stride": 1,
    "baseline_window": 0.5,
    "notch_filter": true,
    "brain_clipping": null,
    "scaling": "both",
    "delay": 0.15,
    "audio_model": "openai/whisper-tiny.en",
    "audio_sample_rate": 16000,
    "hop_length": 160,
    "learning_rate": 0.0003,
    "weight_decay": 0.0001,
    "batch_size": 256,
    "epochs": 50,
    "random_test_size": 10,
    "seed": 42,
    "steps_per_epoch": 450,
    "mel_alignment_objectives": {
        "clip_loss": 0.6,
        "mse_loss": 0.4
    },
    "latent_alignment_objectives": {
        "cosine_similarity": 0.0,
        "mse_loss": 0.0,
        "clip_loss": 0.0,
        "mmd_loss": 0.0
    },
    "decode_timestamps": true,
    "brain_encoder_config": {
        "initial_batch_norm": true,
        "conditions": {
            "study": [
                "gwilliams2023"
            ],
            "subject": [
                "Gwilliams2023_16",
                "Gwilliams2023_18",
                "Gwilliams2023_20",
                "Gwilliams2023_11",
                "Gwilliams2023_26",
                "Gwilliams2023_08",
                "Gwilliams2023_27",
                "Gwilliams2023_25",
                "Gwilliams2023_14",
                "Gwilliams2023_02",
                "Gwilliams2023_21",
                "Gwilliams2023_15",
                "Gwilliams2023_23",
                "Gwilliams2023_01",
                "Gwilliams2023_19",
                "Gwilliams2023_03",
                "Gwilliams2023_09",
                "Gwilliams2023_24",
                "Gwilliams2023_22",
                "Gwilliams2023_06",
                "Gwilliams2023_05",
                "Gwilliams2023_07",
                "Gwilliams2023_12",
                "Gwilliams2023_10",
                "Gwilliams2023_17",
                "Gwilliams2023_04",
                "Gwilliams2023_13"
            ]
        },
        "mel_normalization": false,
        "in_channels": 208,
        "out_channels": 80,
        "hidden_dim": 256,
        "dropout": 0.2,
        "layout_dim": 2,
        "layout_proj": true,
        "layout_scaling": "minmax",
        "merger": false,
        "merger_emb_type": null,
        "merger_emb_dim": 0,
        "merger_channels": 0,
        "merger_dropout": 0.0,
        "merger_conditional": null,
        "initial_linear": 256,
        "initial_depth": 1,
        "conditional_layers": false,
        "conditional_layers_dim": null,
        "depth": 4,
        "kernel_size": 3,
        "growth": 1.0,
        "dilation_growth": 2,
        "dilation_period": 5,
        "glu": 1,
        "dropout_input": 0.1,
        "conv_dropout": 0.2,
        "batch_norm": true,
        "half": true,
        "cnn_pos_encoding": false,
        "quantizer": false,
        "num_codebooks": 0,
        "codebook_size": 0,
        "quantizer_commitment": 0,
        "quantizer_temp_init": 0,
        "quantizer_temp_min": 0,
        "quantizer_temp_decay": 0,
        "transformer_input": "continuous",
        "transformer_encoder_emb": "sinusoidal",
        "transformer_encoder_layers": 4,
        "transformer_encoder_heads": 4,
        "rnn_type": "conformer",
        "depthwise_conv_kernel_size": 15,
        "use_group_norm": false,
        "convolution_first": false,
        "transformer_decoder_emb": null,
        "transformer_decoder_layers": 0,
        "transformer_decoder_heads": 0,
        "transformer_decoder_dim": 0
    }
}