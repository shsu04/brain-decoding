{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 21:41:53,721\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "from studies.study_factory import StudyFactory\n",
    "from dataloader.dataloader import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    buffer_size=10,\n",
    "    max_cache_size_gb=100,\n",
    "    cache_dir=\"cache\",\n",
    "    notch_filter=True,\n",
    "    frequency_bands={\"all\": (0.5, 100)},\n",
    "    scaling=\"both\",\n",
    "    brain_clipping=20,\n",
    "    baseline_window=0.5,\n",
    "    new_freq=100,\n",
    "    batch_types={\"audio\": 3},\n",
    "    batch_kwargs={\n",
    "        'audio': {\n",
    "            'max_random_shift': 1,\n",
    "            'window_size': 4,\n",
    "            'window_stride': 1, \n",
    "            'audio_sample_rate': 16000,\n",
    "            'hop_length': 160,\n",
    "            'audio_processor': \"openai/whisper-large-v3\"\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleConv: \n",
      "\tParams: 10496384\n",
      "\tConv blocks: 5\n",
      "\tTrans layers: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (256) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m layout \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m208\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     10\u001b[0m subjects \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubjects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/brain/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/brain/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Brain/brain-decoding/models/simpleconv.py:175\u001b[0m, in \u001b[0;36mSimpleConv.forward\u001b[0;34m(self, x, layout, subjects)\u001b[0m\n\u001b[1;32m    172\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconditional_layers(x, subjects)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# CNN\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Transformers\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoders:\n",
      "File \u001b[0;32m~/miniconda3/envs/brain/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/brain/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Brain/brain-decoding/models/common.py:404\u001b[0m, in \u001b[0;36mConvSequence.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    401\u001b[0m x \u001b[38;5;241m=\u001b[39m module(x)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# Residual\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mold_x\u001b[49m\n\u001b[1;32m    406\u001b[0m glu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglus[module_idx]\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m glu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (256) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from models.simpleconv import SimpleConv\n",
    "from config.simpleconv_config import SimpleConvConfig\n",
    "import torch\n",
    "\n",
    "config = SimpleConvConfig()\n",
    "model = SimpleConv(config)\n",
    "\n",
    "inputs = torch.randn(3, 208, 400)\n",
    "layout = torch.randn(208, 2)\n",
    "subjects = torch.tensor([0, 1, 2])\n",
    "\n",
    "outputs = model(inputs, layout, subjects)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gwilliams2023 with batch type audio\n"
     ]
    }
   ],
   "source": [
    "study = StudyFactory.create_study(\n",
    "    study_name='gwilliams2023',\n",
    "    batch_type='audio',\n",
    "    path='data/gwilliams2023',\n",
    "    cache_enabled=True,\n",
    "    max_cache_size=200, # in items\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = []\n",
    "\n",
    "# Unfold all recordings (3 dim) of python list to 1\n",
    "from itertools import chain\n",
    "import random\n",
    "\n",
    "flat_recordings = list(chain.from_iterable(chain.from_iterable(study.recordings)))\n",
    "# random.shuffle(flat_recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total recordings: 196\n",
      "Batch shape: 198\n",
      "Batch shape: 425\n",
      "Batch shape: 201\n",
      "Batch shape: 735\n",
      "Batch shape: 421\n",
      "Batch shape: 199\n",
      "Batch shape: 1083\n",
      "Batch shape: 1068\n",
      "Batch shape: 728\n",
      "Batch shape: 1081\n",
      "Batch shape: 423\n",
      "Batch shape: 720\n",
      "Batch shape: 196\n",
      "Batch shape: 421\n",
      "Batch shape: 731\n",
      "Batch shape: 195\n",
      "Batch shape: 421\n",
      "Batch shape: 201\n",
      "Batch shape: 1076\n",
      "Batch shape: 1086\n",
      "Batch shape: 726\n",
      "Batch shape: 1084\n",
      "Batch shape: 428\n",
      "Batch shape: 733\n",
      "Batch shape: 206\n",
      "Batch shape: 424\n",
      "Batch shape: 727\n",
      "Batch shape: 203\n",
      "Batch shape: 425\n",
      "Batch shape: 203\n",
      "Batch shape: 1087\n",
      "Batch shape: 1083\n",
      "Batch shape: 731\n",
      "Batch shape: 1075\n",
      "Batch shape: 418\n",
      "Batch shape: 739\n",
      "Batch shape: 200\n",
      "Batch shape: 426\n",
      "Batch shape: 730\n",
      "Batch shape: 202\n",
      "Batch shape: 417\n",
      "Batch shape: 207\n",
      "Batch shape: 1077\n",
      "Batch shape: 1084\n",
      "Batch shape: 727\n",
      "Batch shape: 1076\n",
      "Batch shape: 416\n",
      "Batch shape: 720\n",
      "Batch shape: 199\n",
      "Batch shape: 424\n",
      "Batch shape: 731\n",
      "Batch shape: 203\n",
      "Batch shape: 422\n",
      "Batch shape: 195\n",
      "Batch shape: 1082\n",
      "Batch shape: 1085\n",
      "Batch shape: 727\n",
      "Batch shape: 1096\n",
      "Batch shape: 421\n",
      "Batch shape: 206\n",
      "Batch shape: 727\n",
      "Batch shape: 723\n",
      "Batch shape: 417\n",
      "Batch shape: 201\n",
      "Batch shape: 425\n",
      "Batch shape: 202\n",
      "Batch shape: 1093\n",
      "Batch shape: 1082\n",
      "Batch shape: 740\n",
      "Batch shape: 1086\n",
      "Batch shape: 417\n",
      "Batch shape: 727\n",
      "Batch shape: 202\n",
      "Batch shape: 421\n",
      "Batch shape: 719\n",
      "Batch shape: 203\n",
      "Batch shape: 430\n",
      "Batch shape: 1079\n",
      "Batch shape: 203\n",
      "Batch shape: 1082\n",
      "Batch shape: 729\n",
      "Batch shape: 1075\n",
      "Batch shape: 423\n",
      "Batch shape: 729\n",
      "Batch shape: 198\n",
      "Batch shape: 425\n",
      "Batch shape: 727\n",
      "Batch shape: 199\n",
      "Batch shape: 417\n",
      "Batch shape: 1076\n",
      "Batch shape: 199\n",
      "Batch shape: 1091\n",
      "Batch shape: 726\n",
      "Batch shape: 1072\n",
      "Batch shape: 424\n",
      "Batch shape: 199\n",
      "Batch shape: 725\n",
      "Batch shape: 726\n",
      "Batch shape: 422\n",
      "Batch shape: 194\n",
      "Batch shape: 419\n",
      "Batch shape: 1072\n",
      "Batch shape: 205\n",
      "Batch shape: 732\n",
      "Batch shape: 1087\n",
      "Batch shape: 428\n",
      "Batch shape: 1086\n",
      "Batch shape: 204\n",
      "Batch shape: 724\n",
      "Batch shape: 420\n",
      "Batch shape: 728\n",
      "Batch shape: 205\n",
      "Batch shape: 1078\n",
      "Batch shape: 423\n",
      "Batch shape: 201\n",
      "Batch shape: 730\n",
      "Batch shape: 1080\n",
      "Batch shape: 417\n",
      "Batch shape: 1083\n",
      "Batch shape: 204\n",
      "Batch shape: 722\n",
      "Batch shape: 424\n",
      "Batch shape: 725\n",
      "Batch shape: 201\n",
      "Batch shape: 1088\n",
      "Batch shape: 428\n",
      "Batch shape: 198\n",
      "Batch shape: 734\n",
      "Batch shape: 1077\n",
      "Batch shape: 425\n",
      "Batch shape: 1073\n",
      "Batch shape: 204\n",
      "Batch shape: 720\n",
      "Batch shape: 415\n",
      "Batch shape: 737\n",
      "Batch shape: 206\n",
      "Batch shape: 1084\n",
      "Batch shape: 416\n",
      "Batch shape: 203\n",
      "Batch shape: 739\n",
      "Batch shape: 1089\n",
      "Batch shape: 417\n",
      "Batch shape: 1078\n",
      "Batch shape: 203\n",
      "Batch shape: 729\n",
      "Batch shape: 427\n",
      "Batch shape: 725\n",
      "Batch shape: 205\n",
      "Batch shape: 1084\n",
      "Batch shape: 416\n",
      "Batch shape: 204\n",
      "Batch shape: 729\n",
      "Batch shape: 1085\n",
      "Batch shape: 417\n",
      "Batch shape: 1085\n",
      "Batch shape: 201\n",
      "Batch shape: 730\n",
      "Batch shape: 417\n",
      "Batch shape: 731\n",
      "Batch shape: 202\n",
      "Batch shape: 1088\n",
      "Batch shape: 429\n",
      "Batch shape: 198\n",
      "Batch shape: 720\n",
      "Batch shape: 1073\n",
      "Batch shape: 423\n",
      "Batch shape: 201\n",
      "Batch shape: 1082\n",
      "Batch shape: 727\n",
      "Batch shape: 425\n",
      "Batch shape: 729\n",
      "Batch shape: 199\n",
      "Batch shape: 1085\n",
      "Batch shape: 425\n",
      "Batch shape: 195\n",
      "Batch shape: 728\n",
      "Batch shape: 1091\n",
      "Batch shape: 419\n",
      "Batch shape: 197\n",
      "Batch shape: 1080\n",
      "Batch shape: 727\n",
      "Batch shape: 418\n",
      "Batch shape: 733\n",
      "Batch shape: 197\n",
      "Batch shape: 1084\n",
      "Batch shape: 419\n",
      "Batch shape: 731\n",
      "Batch shape: 1079\n",
      "Batch shape: 201\n",
      "Batch shape: 426\n",
      "Batch shape: 723\n",
      "Batch shape: 1072\n",
      "Batch shape: 204\n",
      "Batch shape: 421\n",
      "Batch shape: 713\n",
      "Batch shape: 1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 2950 MiB, 8 objects, write throughput 2177 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
     ]
    }
   ],
   "source": [
    "# # Start background fetching\n",
    "import time\n",
    "\n",
    "\n",
    "dataloader.start_fetching(flat_recordings, cache=True)\n",
    "\n",
    "# Process batches as they become available\n",
    "try:\n",
    "    batches, recs, start_time = 0, 0, time.time()\n",
    "    print(f'Total recordings: {len(flat_recordings)}')\n",
    "    \n",
    "    while True:\n",
    "        batch = dataloader.get_recording()\n",
    "        \n",
    "        if batch is None:\n",
    "            break\n",
    "        \n",
    "        brain = batch.brain_segments['all']\n",
    "        \n",
    "        print(f\"Batch shape: {brain.shape[0]}\")\n",
    "        # batches += brain.shape[0]\n",
    "        # recs += 1\n",
    "        \n",
    "        # if recs % 10 == 0:\n",
    "        #     print(f\"Batch {batches} ({recs} recordings) processed in {time.time() - start_time:.2f}s\")\n",
    "        #     print(\n",
    "        #         f\"Average processing time per recording: {(time.time() - start_time) / recs:.2f}s\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"Average processing time per batch: {(time.time() - start_time) / batches:.2f}s\"\n",
    "        #     )\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted\")\n",
    "    dataloader.stop()\n",
    "except Exception as e:\n",
    "    print(\"Error\", e)\n",
    "    dataloader.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
