{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batch workers exceed resources. Reducing by ratio 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 03:48:33,922\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "from studies.study_factory import StudyFactory\n",
    "from dataloader.dataloader import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    buffer_size=10,\n",
    "    max_cache_size_gb=100,\n",
    "    cache_dir=\"cache\",\n",
    "    notch_filter=True,\n",
    "    frequency_bands={\"all\": (0.5, 40)},\n",
    "    scaling=\"both\",\n",
    "    brain_clipping=20,\n",
    "    baseline_window=0.5,\n",
    "    new_freq=100,\n",
    "    batch_types={\"audio\": 100},\n",
    "    batch_kwargs={\n",
    "        'audio': {\n",
    "            'max_random_shift': 1,\n",
    "            'window_size': 4,\n",
    "            'window_stride': 1, \n",
    "            'audio_sample_rate': 16000,\n",
    "            'hop_length': 160,\n",
    "            'audio_processor': \"openai/whisper-large-v3\"\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GWilliams2023 with batch type audio\n"
     ]
    }
   ],
   "source": [
    "study = StudyFactory.create_study(\n",
    "    study_name='gwilliams2023',\n",
    "    batch_type='audio',\n",
    "    path='data/gwilliams2023',\n",
    "    cache_enabled=True,\n",
    "    max_cache_size=200, # in items\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = []\n",
    "\n",
    "# Unfold all recordings (3 dim) of python list to 1\n",
    "from itertools import chain\n",
    "import random\n",
    "\n",
    "flat_recordings = list(chain.from_iterable(chain.from_iterable(study.recordings)))\n",
    "random.shuffle(flat_recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_14_ses_0_task_0.pt loaded with 154 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_24_ses_0_task_0.pt loaded with 153 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_16_ses_1_task_1.pt loaded with 322 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_24_ses_1_task_1.pt loaded with 323 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_22_ses_0_task_1.pt loaded with 309 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_25_ses_1_task_1.pt loaded with 316 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_4_ses_1_task_0.pt loaded with 158 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_10_ses_0_task_0.pt loaded with 148 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_22_ses_0_task_2.pt loaded with 550 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_7_ses_0_task_2.pt loaded with 558 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_16_ses_1_task_2.pt loaded with 552 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_21_ses_1_task_0.pt loaded with 148 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_4_ses_0_task_0.pt loaded with 143 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_11_ses_0_task_0.pt loaded with 157 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_17_ses_0_task_1.pt loaded with 314 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_13_ses_1_task_0.pt loaded with 150 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_1_ses_1_task_0.pt loaded with 150 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_8_ses_0_task_2.pt loaded with 543 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_25_ses_1_task_3.pt loaded with 803 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_14_ses_0_task_3.pt loaded with 825 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_13_ses_1_task_3.pt loaded with 820 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_3_ses_1_task_0.pt loaded with 150 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_9_ses_0_task_1.pt loaded with 320 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_0_ses_1_task_1.pt loaded with 318 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_10_ses_1_task_3.pt loaded with 826 windows.\n",
      "/Users/s.hsu/Brain/brain-decoding/cache/gwilliams2023/sub_0_ses_0_task_0.pt loaded with 150 windows.\n",
      "Interrupted\n"
     ]
    }
   ],
   "source": [
    "# # Start background fetching\n",
    "dataloader.start_fetching(flat_recordings, cache=True)\n",
    "\n",
    "# Process batches as they become available\n",
    "try:\n",
    "    while True:\n",
    "        batch = dataloader.get_recording()\n",
    "        \n",
    "        if batch is None:\n",
    "            break\n",
    "        \n",
    "        brain = batch.brain_segments['all']\n",
    "        print(\n",
    "            f'{batch.recording.cache_path} loaded with {brain.shape[0]} windows.'\n",
    "        )\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted\")\n",
    "    dataloader.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
