{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.compression import compress_directories, decompress_directories\n",
    "\n",
    "# base_path = \"downloaded_data/gwilliams\"\n",
    "# destination_path = \"data/gwilliams\"\n",
    "\n",
    "# decompress_directories(\n",
    "#     base_path,\n",
    "#     destination_path,\n",
    "#     checksum_file_name=\"checksums.txt\",\n",
    "#     delete_compressed_files=True,\n",
    "#     num_workers=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data partitioned on studies ['gwilliams']. Recordings:\n",
      "Train: 135, Unseen Task: 12, Unseen Subject: 45, Unseen Both: 4.\n",
      "\n",
      "\n",
      "SimpleConv: \n",
      "\tParams: 14432128\n",
      "\tConv blocks: 5\n",
      "\tTrans layers: 0\n"
     ]
    }
   ],
   "source": [
    "from config.simpleconv_config import SimpleConvConfig\n",
    "from models.simpleconv import SimpleConv\n",
    "from studies.study_factory import StudyFactory\n",
    "from utils.pre_processor import PreProcessor\n",
    "from utils.fetch import fetch_audio_and_brain_pairs\n",
    "import typing as tp\n",
    "import json\n",
    "from itertools import product\n",
    "from torch.optim import AdamW, Adam\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "device = 'cuda'\n",
    "\n",
    "from config import SimpleConvConfig, Config\n",
    "\n",
    "class TrainingConfigV0(Config):\n",
    "    def __init__(\n",
    "        self,\n",
    "        brain_encoder_config: SimpleConvConfig,\n",
    "        data_partition: tp.Dict[str, tp.Dict[str, tp.List[str]]],\n",
    "        # Pre-processing parameters\n",
    "        # Brain\n",
    "        brain_sample_rate: int = 100,\n",
    "        band_pass_filter: tp.Tuple[str, tp.Tuple[int, int]] = {\"all\": (0.5, 100)},\n",
    "        max_random_shift: float = 2.0,\n",
    "        window_size: int = 4,\n",
    "        window_stride: int = 1,\n",
    "        brain_clipping: float = 20,\n",
    "        baseline_window: int = 0.5,\n",
    "        notch_filter: bool = True,\n",
    "        # Audio\n",
    "        audio_model: str = \"openai/whisper-large-v3\",\n",
    "        audio_sample_rate: int = 16000,\n",
    "        hop_length: int = 160,\n",
    "        \n",
    "        # Hyperparameters\n",
    "        learning_rate: float = 3e-4,\n",
    "        weight_decay: float = 1e-4,\n",
    "    ):\n",
    "        self.brain_encoder_config = brain_encoder_config\n",
    "        # key: study_name, value: dict with keys: \"testing_subjects\", \"testing_tasks\",\n",
    "        # where each value is a list of int. Ones not specified in either lists are \n",
    "        # used for training.\n",
    "        self.data_partition = data_partition\n",
    "        \n",
    "        # Pre-processing parameters\n",
    "        # Brain\n",
    "        self.brain_sample_rate = brain_sample_rate\n",
    "        self.band_pass_filter = band_pass_filter\n",
    "        self.max_random_shift = max_random_shift\n",
    "        self.window_size = window_size\n",
    "        self.window_stride = window_stride\n",
    "        self.baseline_window = baseline_window\n",
    "        self.notch_filter = notch_filter\n",
    "        # Audio\n",
    "        self.audio_model = audio_model\n",
    "        self.audio_sample_rate = audio_sample_rate\n",
    "        self.hop_length = hop_length\n",
    "        self.brain_clipping = brain_clipping\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "    # does not overide parent method\n",
    "    def to_dict_(self):\n",
    "        brain_encoder_config = self.brain_encoder_config.to_dict()\n",
    "        config = self.to_dict()\n",
    "        config[\"brain_encoder_config\"] = brain_encoder_config\n",
    "        return config\n",
    "\n",
    "        \n",
    "class TrainingSessionV0:\n",
    "    def __init__(self,\n",
    "        config: TrainingConfigV0,\n",
    "        studies: tp.List[str],\n",
    "        data_path: str = '/home/ubuntu/brain-decoding/data',\n",
    "        save_path: str = '/home/ubuntu/brain-decoding/saves',\n",
    "    ):\n",
    "        \"\"\"Initializes a training session with the provided configuration and data.\n",
    "\n",
    "        Arguments:\n",
    "            config -- The configuration for the training session.\n",
    "            studies -- list of studies to train on. Partition policy determined in TrainingConfig\n",
    "            data_path -- The path to the data directory.\n",
    "            save_path -- The path to the directory where the model and logs will be saved.\n",
    "        \"\"\"\n",
    "        assert len(studies) > 0, \"At least one study root path must be provided\"\n",
    "        assert all(\n",
    "            os.path.exists(data_path + \"/\" + study) for study in studies\n",
    "        ), \"All study root paths must exist\"\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "            \n",
    "        logging.basicConfig(\n",
    "            filename=os.path.join(save_path, \"training_log.log\"),\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s %(message)s\",\n",
    "            filemode=\"w\",\n",
    "        )\n",
    "        self.logger = logging.getLogger()\n",
    "\n",
    "        self.config = config\n",
    "        self.data_path = data_path\n",
    "        self.save_path = save_path\n",
    "        \n",
    "        # Create studies accessor\n",
    "        self.studies = {}\n",
    "        for study in studies:\n",
    "            path = os.path.join(data_path, study)\n",
    "            try:\n",
    "                self.studies[study] = StudyFactory.create_study(study, path)\n",
    "            except ValueError as e:\n",
    "                self.logger.error(f\"Error loading study {study}: {e}\")\n",
    "                \n",
    "        # Create preprocessor\n",
    "        self.pre_processor = PreProcessor(\n",
    "            brain_sample_rate=config.brain_sample_rate, \n",
    "            audio_model=config.audio_model\n",
    "        )\n",
    "\n",
    "        self.dataset = {\n",
    "            \"train\": [],\n",
    "            \"test\": {\n",
    "                \"unseen_subject\": [],\n",
    "                \"unseen_task\": [],\n",
    "                \"unseen_both\": [],\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        self.partition_data()\n",
    "        \n",
    "        self.metrics = {\n",
    "            \"train\": [],\n",
    "            \"test\": {\n",
    "                \"unseen_subject\": [],\n",
    "                \"unseen_task\": [],\n",
    "                \"unseen_both\": [],\n",
    "            },\n",
    "        }\n",
    "\n",
    "        self.model = SimpleConv(self.config.brain_encoder_config)\n",
    "        self.error = None\n",
    "        self.optimizer = Adam(\n",
    "            self.model.parameters(), \n",
    "            lr=self.config.learning_rate, \n",
    "            weight_decay=self.config.weight_decay\n",
    "        )\n",
    "\n",
    "    def partition_data(self):\n",
    "        \"\"\"\n",
    "        Partitions the data into training and various testing sets, based on \n",
    "        the named holdout sessions and tasks specified in TrainingConfig\n",
    "        \"\"\"\n",
    "        \n",
    "        for study_name, study in self.studies.items():\n",
    "            \n",
    "            if study_name not in self.config.data_partition:\n",
    "                raise ValueError(f\"Study {study_name} not found in data partition\")\n",
    "\n",
    "            data_partition = self.config.data_partition[study_name]\n",
    "            \n",
    "            for subject, task, session in product(\n",
    "                [i for i in range(len(study.subjects_list))],\n",
    "                [i for i in range(len(study.tasks))],\n",
    "                [i for i in range(len(study.sessions))],\n",
    "            ):\n",
    "                # If recording exists\n",
    "                try:\n",
    "                    recording = study.recordings[subject][task][session]\n",
    "                except IndexError:\n",
    "                    self.logger.error(f\"Recording not found for {study_name} {subject} {task} {session}\")\n",
    "                    continue\n",
    "                \n",
    "                # Unseen both and task\n",
    "                if subject in data_partition[\"testing_subjects\"]:\n",
    "                    if task in data_partition[\"testing_tasks\"]:\n",
    "                        self.dataset[\"test\"][\"unseen_both\"].append((study_name, subject, task, session))\n",
    "                    else:\n",
    "                        self.dataset[\"test\"][\"unseen_task\"].append((study_name, subject, task, session))\n",
    "                # Unseen subject and train\n",
    "                else:\n",
    "                    if task in data_partition[\"testing_tasks\"]:\n",
    "                        self.dataset[\"test\"][\"unseen_subject\"].append((study_name, subject, task, session))\n",
    "                    else:\n",
    "                        self.dataset[\"train\"].append((study_name, subject, task, session))\n",
    "                          \n",
    "        self.log_print(\n",
    "            f'Data partitioned on studies {list(self.studies.keys())}. Recordings:'\n",
    "        )\n",
    "        self.log_print(\n",
    "            f\"Train: {len(self.dataset['train'])}, Unseen Task: {len(self.dataset['test']['unseen_task'])}, Unseen Subject: {len(self.dataset['test']['unseen_subject'])}, Unseen Both: {len(self.dataset['test']['unseen_both'])}.\\n\"\n",
    "        )\n",
    "        \n",
    "    def train(self, device: str):\n",
    "        pass\n",
    "    \n",
    "    def test(self, device: str):\n",
    "        pass\n",
    "    \n",
    "    def pre_process_all_tasks(self):\n",
    "        pass\n",
    "    \n",
    "    def load_task(self):\n",
    "        pass\n",
    "    \n",
    "    def run_task(self):\n",
    "        pass\n",
    "    \n",
    "    def save(self):\n",
    "        pass\n",
    "    \n",
    "    def discard_nan(self):\n",
    "        pass\n",
    "        \n",
    "    def log_print(self, message):\n",
    "        print(message)\n",
    "        self.logger.info(message) \n",
    "        \n",
    "def load_training_session(): pass\n",
    "        \n",
    "training_config = TrainingConfigV0(\n",
    "    brain_encoder_config=SimpleConvConfig(),\n",
    "    data_partition={\n",
    "        \"gwilliams\": {\n",
    "            \"testing_subjects\": [19, 20, 21],\n",
    "            \"testing_tasks\": [0],\n",
    "        },\n",
    "        # \"schoffelen\": {\n",
    "        #     \"testing_subjects\": [],\n",
    "        #     \"testing_tasks\": [8, 9],\n",
    "        # },\n",
    "    },\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=1e-4,\n",
    ")      \n",
    "\n",
    "session = TrainingSessionV0(\n",
    "    training_config,\n",
    "    studies=[\"gwilliams\"], # \"schoffelen\"\n",
    "    data_path='/home/ubuntu/brain-decoding/data',\n",
    "    save_path='/home/ubuntu/brain-decoding/saves'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_sample_rate = 100\n",
    "frequency_bands = {\"all\": (0.5, 100)}\n",
    "subject, task, session = 0, 3, 0\n",
    "seed = 42\n",
    "max_random_shift = 1\n",
    "window_size = 4\n",
    "n_jobs = -1\n",
    "\n",
    "study = StudyFactory().create_study(\"gwilliams\", path=\"data/gwilliams\")\n",
    "pre_processor = PreProcessor(\n",
    "    brain_sample_rate=brain_sample_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.subjects_list[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1094, 208, 400]),\n",
       " torch.Size([1094, 128, 400]),\n",
       " torch.Size([208, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_segments, audio_segments, layout = fetch_audio_and_brain_pairs(\n",
    "    subject=subject,\n",
    "    task=task,\n",
    "    session=session,\n",
    "    max_random_shift=max_random_shift,\n",
    "    window_size=window_size,\n",
    "    study=study,\n",
    "    pre_processor=pre_processor,\n",
    "    frequency_bands=frequency_bands,\n",
    "    audio_sample_rate=16000,\n",
    "    hop_length=160,\n",
    "    n_jobs=n_jobs,\n",
    ")\n",
    "brain_segments['all'].shape, audio_segments.shape, layout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleConv: \n",
      "\tParams: 14432128\n",
      "\tConv blocks: 5\n",
      "\tTrans layers: 0\n"
     ]
    }
   ],
   "source": [
    "model = SimpleConv(SimpleConvConfig(transformer_layers=0)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(\n",
    "    {\"meg\": brain_segments[\"all\"].to(device)},\n",
    "    layout=layout.to(device),\n",
    "    subjects=torch.full((brain_segments[\"all\"].shape[0],), subject).to(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([199, 128, 400])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
